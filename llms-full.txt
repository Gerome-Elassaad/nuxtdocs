# Introduction

![CodinIT Platform](https://codinit.dev/opengraph.png){style="border-radius: 12px; max-width: 100%;"}

## Platform Capabilities

The platform provides all the tools you need to create amazing websites, front-end applications as well as full-stack web applications from one browser tab - no installation required. CodinIT includes AI coding tools, real-time collaboration, and project sharing to give you a head start on your app creation journey.

| Capability       | Description                                 | Maturity Level |
| ---------------- | ------------------------------------------- | -------------- |
| Frontend / UI    | Build user interfaces & frontend            | üü¢ Mature      |
| Persistence      | Store and retrieve data                     | üü¢ Mature      |
| Authentication   | Handle user login and accounts              | üü¢ Mature      |
| Backend endpoint | API key protected endpoint such as OpenAI   | üü¢ Mature      |
| Deployment       | Publish, custom domains & deploy            | üü¢ Mature      |
| Collaboration    | Collaborate with other users within project | üü¢ Mature      |
| Real-time sync   | Sync data across users in real-time         | üü¢ Mature      |

## Quick Start Journey

To create your app on CodinIT, choose the guide that matches your needs:

::steps{level="3"}
### Tutorial

Step-by-step tutorial for a simple introduction to key features and concepts.

### Integrations

Go beyond default features by integrating with third parties like Supabase, Stripe or others.

### Prompt Engineering

Learn effective prompting strategies and get the most out of CodinIT.

### Custom Domain

Add your own domain to any CodinIT site app.

### Deploy

Learn how to deploy, share, and get traffic to your web applications with CodinIT.
::

## What is CodinIT

::callout{color="primary"}
**Letting Ordinary Visionaries Achieve Breakthroughs with Language-based Engineering.**

CodinIT is an AI-powered platform that lets you create and deploy apps from a single browser tab. The platform eliminates the complexity of traditional app-creation environments by combining coding, deployment, and collaboration tools in a single interface.
::

Typically, you must install programs, languages, and packages to build apps. However, on CodinIT, you can rely on AI to configure your environment so you can start building without coding experience.

The platform supports full-featured development and coding environments for those familiar with coding as well as those who are not, so there's no limit on what's possible.

### Key Features

- **Complete app generation** and setup from natural language description
- **Code suggestions** and autocomplete with AI assistance
- **Automated error detection** and debugging assistance
- **Documentation generation** for your applications
- **App deployment** to the cloud in a few clicks
- **Database integration** and hosting with Supabase native integration
- **Custom domain support** and connection

Your development environment structure will look like this:

```text
codinit-project/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îî‚îÄ‚îÄ config.json
```

## Essential Resources

::card-group
  :::card
  ---
  ariaLabel: Browse and use project templates
  icon: i-lucide-folder-open
  title: Templates
  ---
  Browse and use project templates to quickly start your next project.
  :::

  :::card
  ---
  ariaLabel: Get a full overview of how to build an app with CodinIT
  icon: i-lucide-play-circle
  title: Tutorial
  ---
  Get a full overview of how to build an app with CodinIT.
  :::

  :::card
  ---
  ariaLabel: Resolve issues in your development lifecycle
  icon: i-lucide-wrench
  title: Troubleshooting
  ---
  Resolve issues in your development lifecycle.
  :::

  :::card
  ---
  ariaLabel: Getting the Most Out of CodinIT
  icon: i-lucide-star
  title: Best Practices
  ---
  Getting the Most Out of CodinIT.
  :::

  :::card
  ---
  ariaLabel: Collaborate on your app in real time with teammates
  icon: i-lucide-users
  title: Teams
  ---
  Collaborate on your app in real time with teammates.
  :::
::

## Stay Connected

### Community & Support

::card-group
  :::card
  ---
  ariaLabel: Share ideas and let the community vote
  icon: i-lucide-lightbulb
  title: Feature Requests
  ---
  Have an idea? Share it and let the community vote
  :::

  :::card
  ---
  ariaLabel: Get help from our Community and Community Champions
  icon: i-lucide-help-circle
  title: Community Support
  ---
  Get help from our Community and Community Champions
  :::

  :::card{ariaLabel="Report a bug or an issue" icon="i-lucide-bug" title="Issues"}
  Found a bug or an issue? Let us know
  :::

  :::card
  ---
  ariaLabel: Direct support channel for paying users
  icon: i-lucide-headphones
  title: Priority Support
  ---
  Direct support channel for paying users
  :::
::

### Programs & Partnerships

::card-group
  :::card
  ---
  ariaLabel: Publish your app to get in front of thousands of people
  icon: i-lucide-rocket
  title: Launched
  ---
  Publish your app to get in front of thousands of people
  :::

  :::card
  ---
  ariaLabel: Join as an expert, or get help from our network of experts
  icon: i-lucide-handshake
  title: Partner Program
  ---
  Join as an expert, or get help from our network of experts
  :::

  :::card
  ---
  ariaLabel: Receive a 20% commission on the first 12 payments
  icon: i-lucide-percent
  title: Affiliate Program
  ---
  Receive a 20% commission on the first 12 payments
  :::
::

### Learn More about CodinIT

::card-group
  :::card
  ---
  ariaLabel: Learn more about CodinIT on our website
  icon: i-lucide-globe
  title: Visit our Website
  to: https://codinit.dev
  ---
  Explore our official website to learn more about CodinIT.
  :::

  :::card
  ---
  ariaLabel: Understand key development terms in our documentation
  icon: i-lucide-book-open
  title: Learn More
  to: https://docs.codinit.dev/getting-started/quickstart
  ---
  Familiarize yourself with key development terms by exploring our Documentation.
  :::

  :::card
  ---
  ariaLabel: prompting with codinit
  icon: i-lucide-briefcase
  title: Find out how to prompt with codinit
  to: https://codinit.dev/blog/prompting-with-codinit
  ---
  Learn how to prompt codinit for best results.
  :::

  :::card
  ---
  ariaLabel: Stay updated with the latest from the CodinIT team
  icon: i-lucide-megaphone
  title: Read Our Blog Announcements
  to: https://codinit.dev/blog
  ---
  Catch up on the latest news and updates from the CodinIT team.
  :::
::

::tip
üéâ Ready to start building? Choose your path from the Quick Start section above and begin creating your next application with CodinIT!
::


# Quickstart

Get your first CodinIT application running in under 10 minutes with this comprehensive quickstart guide.

::alert{color="green" icon="i-lucide-rocket"}
**New to CodinIT?** This guide walks you through the complete workflow from project creation to deployment.
::

## Create Your First Project

::steps{level="4"}
#### Step 1: Start a New Project

Navigate to your CodinIT dashboard and click **"Create New Project"**. Choose from:

- üì± **Mobile App** ‚Äì Responsive mobile-first applications
- üåê **Web Application** ‚Äì Full-stack web apps with backend
- üé® **Landing Page** ‚Äì Marketing sites and portfolios
- üìä **Dashboard** ‚Äì Data visualization and admin panels

#### Step 2: Describe Your App

Use natural language to describe what you want to build:

```text
Create a task management app with user authentication, 
the ability to add, edit, and delete tasks, and a 
dashboard showing task statistics.
```

#### Step 3: Review Generated Code

CodinIT will generate your complete application. Review the:

- Frontend components and styling
- Backend API endpoints
- Database schema and models
- Authentication setup

#### Step 4: Customize and Iterate

Make changes using natural language prompts or direct code editing:

```text
Add a priority system to tasks with high, medium, low options.
Style the app with a dark theme and modern card layout.
```
::

## Essential Editing Features

::card-group
  :::card{icon="i-lucide-edit" title="AI-Powered Editing"}
  Make changes using natural language prompts with instant preview
  :::

  :::card{icon="i-lucide-eye" title="Visual Editor"}
  Click and edit components directly with AI-driven visual controls
  :::

  :::card{icon="i-lucide-undo" title="Version Control"}
  Restore past versions instantly and bookmark important milestones
  :::

  :::card{icon="i-lucide-sparkles" title="Smart Suggestions"}
  Get AI suggestions for improvements and feature additions
  :::

  :::card{icon="i-lucide-image-plus" title="Media Integration"}
  Attach images and files directly to prompts for better context
  :::

  :::card{icon="i-lucide-layers" title="Component Library"}
  Access pre-built components and templates for faster development
  :::
::

## Knowledge Base Setup

Organize your project information for better AI assistance:

::steps{level="4"}
#### Step 1: Access Knowledge Base

Go to the Knowledge Base section in your dashboard.

#### Step 2: Add Project Documentation

Click "Add Entry" and categorize information under:

- üìå **Project Overview** ‚Äì Define objectives and scope
- üöÄ **Key Features** ‚Äì List core functionalities
- üé® **Design Guidelines** ‚Äì Document UI/UX principles
- üîß **Technical Requirements** ‚Äì Specify technologies and constraints

#### Step 3: Keep Information Current

Regularly review and update entries as your project evolves to ensure development stays aligned with your vision.
::

## Add Backend Capabilities

### Connect with Supabase

Supabase integration provides powerful backend capabilities with minimal setup:

::steps{level="4"}
#### Step 1: Create Supabase Project

Create an account on [Supabase](https://supabase.com){ariaLabel="Supabase Website" rel="nofollow"} and set up a new project.

#### Step 2: Link to CodinIT

In CodinIT, navigate to Settings ‚Üí Connect Supabase and follow the integration steps.

#### Step 3: Configure Data Models

Set up database tables, manage user data, and configure real-time subscriptions.

#### Step 4: Enable Authentication

Configure user authentication flows including email verification and social logins.
::

### Authentication Implementation

::tabs
  :::div{label="Setup Process"}
  **Step 1: Supabase Account Creation**
  
  Visit Supabase and sign up to access the project dashboard.
  
  **Step 2: Integration Configuration**
  
  Input your Supabase project URL and API keys to establish connection.
  
  **Step 3: Authentication Forms**
  
  Use CodinIT's AI form builder to create intuitive login and registration forms.
  
  **Step 4: Workflow Implementation**
  
  Set up Supabase Edge Functions for token validation and session management.
  :::

  :::div{label="Advanced Features"}
  **Email Verification**
  
  Configure automated email verification upon user registration.
  
  **Social Authentication**
  
  Enable Google, GitHub, and other OAuth provider integrations.
  
  **Role-Based Access**
  
  Implement user roles and permissions for secure access control.
  
  **Session Management**
  
  Handle user sessions with automatic refresh and secure logout.
  :::
::

## Testing and Deployment

### Preview Your Application

::alert{color="blue" icon="i-lucide-monitor"}
**Live Preview** - Every change is instantly reflected in the preview pane, allowing you to test functionality in real-time.
::

- **Responsive Testing** ‚Äì Check how your app looks on different device sizes
- **Feature Testing** ‚Äì Test user flows and interactions
- **Performance Monitoring** ‚Äì Monitor loading times and responsiveness

### Deploy to Production

::steps{level="3"}
### Step 1: Pre-Deployment Check

Review your application for:

- Functionality completeness
- Responsive design across devices
- Performance optimization
- Error handling

### Step 2: Choose Deployment Option

Select from multiple deployment options:

- **CodinIT Hosting** ‚Äì Instant deployment with custom domain support
- **GitHub Integration** ‚Äì Deploy via GitHub Pages or other CI/CD platforms
- **Custom Hosting** ‚Äì Export code for deployment anywhere

### Step 3: Configure Custom Domain

Add your custom domain for professional deployment:

- Point your domain to CodinIT's servers
- Configure SSL certificates automatically
- Set up redirect rules and routing
::

## Next Steps

::card-group
  :::card
  ---
  ariaLabel: Learn about team collaboration features
  icon: i-lucide-users
  title: Team Collaboration
  to: https://docs.codinit.dev/getting-started/teams
  ---
  Invite team members and collaborate in real-time
  :::

  :::card
  ---
  ariaLabel: Connect with third-party services and APIs
  icon: i-lucide-puzzle
  title: Integrations
  to: https://docs.codinit.dev/integrations/github
  ---
  Connect with third-party services and APIs
  :::

  :::card
  ---
  ariaLabel: Explore framework-specific development resources
  icon: i-lucide-code
  title: Developer Tools
  to: https://docs.codinit.dev/getting-started/developer-docs
  ---
  Explore framework-specific development resources
  :::
::

::tip
üéâ **Congratulations!** You've completed the quickstart guide. Your application is ready for further development and customization. Explore the advanced features to build even more powerful applications.
::


# Teams

CodinIT lets you build apps together, live. Invite your designer, developer, agency, or anyone else to your workspace. Everyone sees changes as they happen in real-time.

::callout{color="blue" icon="i-lucide-users"}
**Collaborative Development** - Experience seamless team collaboration with real-time editing, shared workspaces, and professional project management tools.
::

## Workspace Plans

Each subscription connects to a workspace with different collaboration capabilities:

::card-group
  :::card{color="primary" icon="i-lucide-user" title="Pro Subscription"}
  Personal workspaces with up to 2 collaborators per project. Collaborators use project owner credits for seamless cost management.
  :::

  :::card{color="green" icon="i-lucide-users" title="Teams Subscription"}
  Up to 20 users in workspace. Owners & admins manage users and projects. Shared credit pool for all team members.
  :::
::

## Workspace Management

### Create a Workspace

A workspace is your shared environment for building and collaborating on projects with your team.

::steps{level="3"}
### Step 1: Create New Workspace

Click **"Create new workspace"** from the dashboard or any existing project.

### Step 2: Name Your Workspace

Choose a descriptive name for your workspace that reflects your team or organization.

### Step 3: Choose a Plan

Select a subscription plan that fits your team size and collaboration requirements.
::

### Rename a Workspace

::steps{level="3"}
### Step 1: Switch to Workspace

Ensure you're in the correct workspace (switch if needed from the sidebar).

### Step 2: Access Settings

Navigate to **Settings** from your workspace dashboard.

### Step 3: Edit Details

Update the **Workspace name** and **description** to reflect changes in your team or project focus.
::

## Team Member Management

### Invite & Manage Collaborators

::steps{level="3"}
### Step 1: Upgrade Your Plan

Upgrade to the **Teams** tier if you're currently on a personal plan.

### Step 2: Send Invitations

Click **"Invite"** in a project or from the main dashboard to access the invitation system.

### Step 3: Add Team Members

Enter email addresses to send invitations to your team members and collaborators.

### Step 4: Team Integration

When invitations are accepted, members join your workspace and gain access to all shared projects.
::

### Role-Based Permissions

Different roles provide varying levels of access and control within your workspace:

| Action                                          | Owner | Admin | Editor |
| ----------------------------------------------- | ----- | ----- | ------ |
| Edit projects                                   | ‚úì     | ‚úì     | ‚úì      |
| Publish projects                                | ‚úì     | ‚úì     | ‚úì      |
| Connect/disconnect Supabase org to workspace    | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect Supabase project to projects | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub org to workspace      | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub repo to projects      | ‚úì     | ‚úì     | ‚úó      |
| Invite project-level collaborators              | ‚úì     | ‚úì     | ‚úó      |
| Transfer projects to other workspaces           | ‚úì     | ‚úì     | ‚úó      |
| Set roles for other users                       | ‚úì     | ‚úì     | ‚úó      |

### Role Descriptions

::field-group
  :::field{name="Owner" type="role"}
  Complete administrative control over the workspace, billing management, and all projects
  :::

  :::field{name="Admin" type="role"}
  Can manage most workspace and project aspects, but cannot modify other admin roles
  :::

  :::field{name="Editor" type="role"}
  Can edit and publish projects but cannot manage workspace settings, integrations, or user permissions
  :::
::

## Real-Time Collaboration Features

Once team members join your workspace, experience seamless real-time collaboration:

::card-group
  :::card
  ---
  ariaLabel: See team member cursors and live changes in real-time
  icon: i-lucide-mouse-pointer
  title: Live Cursors
  ---
  See team member cursors and live changes as they work in real-time
  :::

  :::card
  ---
  ariaLabel: Icons show who's currently online and active
  icon: i-lucide-circle-dot
  title: Team Presence
  ---
  Icons in top-right corner show who's currently online and active
  :::

  :::card
  ---
  ariaLabel: Edit any element together with immediate synchronization
  icon: i-lucide-edit
  title: Instant Editing
  ---
  Edit any element together with immediate synchronization across all users
  :::

  :::card
  ---
  ariaLabel: All modifications reflected immediately across all team members' screens
  icon: i-lucide-refresh-cw
  title: Change Synchronization
  ---
  All modifications reflected immediately across all team members' screens
  :::
::


# Developer Docs

Framework-focused prompting strategies and development patterns for building applications with CodinIT. Each section provides proven patterns, best practices, and ready-to-use prompts tailored to specific technology stacks.

::callout{color="blue" icon="i-heroicons-code-bracket"}
**Framework-Focused Prompts** - Specialized prompt patterns for Next.js, Python, Gradio, and Streamlit development. Copy, modify, and use these templates to build better applications faster.
::

## Overview

This library provides targeted prompting strategies for specific development frameworks. Each section contains proven patterns, best practices, and ready-to-use prompts tailored to the unique characteristics of each technology stack.

::alert{color="green" icon="i-heroicons-light-bulb"}
**Pro Tip** - These prompts are designed to work with any AI coding assistant. Adapt the examples to your specific project needs and requirements.
::

## Supported Frameworks

::card-group{cols="2"}
  :::card
  ---
  ariaLabel: Learn about Next.js Development
  icon: i-simple-icons-nextdotjs
  title: Next.js Development
  ---
  Full-stack React framework with SSR, API routes, and modern tooling for web applications.
  
  :badge[React]{color="blue" variant="outline"} :badge[TypeScript]{color="blue" variant="outline"} :badge[Full-Stack]{color="green" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Python Development
  icon: i-simple-icons-python
  title: Python Development
  ---
  Backend services, data processing, and general-purpose application development.
  
  :badge[Backend]{color="orange" variant="outline"} :badge[Data Science]{color="purple" variant="outline"} :badge[APIs]{color="emerald" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Gradio Development
  icon: i-heroicons-chart-bar
  title: Gradio Development
  ---
  Rapid ML model deployment and interactive data science applications.
  
  :badge[ML/AI]{color="red" variant="outline"} :badge[Interactive]{color="cyan" variant="outline"} :badge[Prototyping]{color="amber" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Streamlit Development
  icon: i-heroicons-presentation-chart-line
  title: Streamlit Development
  ---
  Data apps and dashboards with Python-first development approach.
  
  :badge[Data Apps]{color="indigo" variant="outline"} :badge[Dashboards]{color="pink" variant="outline"} :badge[Analytics]{color="teal" variant="outline"}
  :::
::

---

## Next.js Development

::callout{color="black" icon="i-simple-icons-nextdotjs"}
**Modern React framework with server-side rendering, API routes, and performance optimization.**
::

### Project Setup & Architecture

::tabs
  :::div{label="New Project Setup"}
  ```markdown
  Create a new Next.js 14 application with the following specifications:
  
  **Tech Stack:**
  - Next.js 14 with App Router
  - TypeScript for type safety
  - Tailwind CSS for styling
  - Prisma with PostgreSQL for database
  - NextAuth.js for authentication
  
  **Project Structure:**
  - `/app` directory structure with proper layouts
  - `/components` for reusable UI components
  - `/lib` for utilities and database configuration
  - `/types` for TypeScript definitions
  
  **Initial Features:**
  - Landing page with hero section and navigation
  - User authentication (sign up, login, logout)
  - Protected dashboard route
  - Responsive design with dark mode support
  
  Set up the basic project structure and create placeholder components.
  ```
  :::

  :::div{label="Component Architecture"}
  ```markdown
  Design a component architecture for a [describe app type] application:
  
  **Component Categories:**
  - UI components (buttons, inputs, cards)
  - Layout components (header, sidebar, footer)
  - Feature components (user profile, product listing)
  - Page components (home, dashboard, settings)
  
  **Requirements:**
  - TypeScript interfaces for all props
  - Compound component patterns where appropriate
  - Accessibility features (ARIA labels, keyboard navigation)
  - Consistent styling with Tailwind CSS variants
  
  Include examples of 2-3 components with proper TypeScript typing.
  ```
  :::
::

---

## Python Development

::callout{color="yellow" icon="i-simple-icons-python"}
**Versatile language for backend development, data processing, and API creation.**
::

### API Development

::tabs
  :::div{label="FastAPI Setup"}
  ```markdown
  Create a FastAPI application with the following requirements:
  
  **Features:**
  - RESTful API with CRUD operations
  - User authentication with JWT tokens
  - Database integration with SQLAlchemy
  - Input validation with Pydantic
  - Automated API documentation
  
  **Structure:**
  - `/models` for database models
  - `/routers` for API endpoints
  - `/schemas` for Pydantic models
  - `/auth` for authentication logic
  
  Include user registration, login, and protected endpoints.
  ```
  :::

  :::div{label="Data Processing"}
  ```markdown
  Build a data processing pipeline that:
  
  **Input Sources:**
  - CSV files from uploads
  - Database queries
  - API endpoints
  
  **Processing Steps:**
  - Data cleaning and validation
  - Statistical analysis
  - Visualization generation
  - Export to multiple formats
  
  **Output:**
  - Processed datasets
  - Summary statistics
  - Interactive charts
  - Automated reports
  
  Use pandas, numpy, and plotly for implementation.
  ```
  :::
::

---

## Gradio Development

::callout{color="red" icon="i-heroicons-chart-bar"}
**Rapid prototyping framework for ML models and interactive demos.**
::

### Interactive ML Applications

::tabs
  :::div{label="Model Demo Interface"}
  ```markdown
  Create a Gradio interface for [ML model type]:
  
  **Interface Components:**
  - File upload for input data
  - Parameter sliders for model tuning
  - Real-time prediction display
  - Confidence scores and explanations
  - Download results functionality
  
  **Features:**
  - Batch processing capabilities
  - Model comparison tools
  - Performance metrics display
  - Error handling and validation
  
  Include examples with sample data and clear instructions.
  ```
  :::

  :::div{label="Data Visualization Dashboard"}
  ```markdown
  Build a Gradio dashboard for data exploration:
  
  **Components:**
  - Dataset upload and preview
  - Interactive charts and plots
  - Statistical summary tables
  - Filter and search capabilities
  - Export functionality
  
  **Visualizations:**
  - Distribution plots
  - Correlation matrices
  - Time series analysis
  - Geographic mapping (if applicable)
  
  Make it responsive and user-friendly for non-technical users.
  ```
  :::
::

---

## Streamlit Development

::callout{color="red" icon="i-heroicons-presentation-chart-line"}
**Python-first framework for building data applications and interactive dashboards.**
::

### Data Dashboards

::tabs
  :::div{label="Analytics Dashboard"}
  ```markdown
  Create a comprehensive analytics dashboard using Streamlit:
  
  **Data Sources:**
  - Multiple data source connections (CSV, database, API)
  - Real-time data refresh capabilities
  - Data caching for performance
  - Error handling for data loading
  
  **Dashboard Layout:**
  - Multi-page application structure
  - Sidebar navigation and filters
  - Responsive grid layout
  - Customizable date ranges
  - Export functionality
  
  **Visualizations:**
  - KPI metrics with st.metric()
  - Interactive charts with Plotly
  - Data tables with filtering/sorting
  - Geographic visualizations
  
  Include caching and performance optimization.
  ```
  :::

  :::div{label="Machine Learning App"}
  ```markdown
  Build a complete ML application with Streamlit:
  
  **Features:**
  - Model training interface
  - Hyperparameter tuning
  - Performance evaluation
  - Prediction interface
  - Model deployment options
  
  **Components:**
  - Data upload and preprocessing
  - Model selection and training
  - Results visualization
  - Model comparison tools
  - Export trained models
  
  Include proper error handling and user guidance.
  ```
  :::
::

---

## Development Best Practices

::alert{color="amber" icon="i-heroicons-star"}
**Quality Assurance** - Follow these practices for professional-grade applications regardless of framework choice.
::

### Code Quality Guidelines

::steps{level="4"}
#### Step 1: Planning & Design

Start with clear requirements and architecture design before implementation.

#### Step 2: Iterative Development

Build features incrementally with regular testing and validation.

#### Step 3: Code Review

Implement peer review processes for maintaining code quality standards.

#### Step 4: Deployment & Monitoring

Set up automated deployment with proper monitoring and error tracking.
::

### Framework Selection Guide

Choose the right framework based on your project requirements:

| Framework     | Best For            | Use Cases                         |
| ------------- | ------------------- | --------------------------------- |
| **Next.js**   | Full-stack web apps | E-commerce, SaaS, Marketing sites |
| **Python**    | Backend services    | APIs, Data processing, Automation |
| **Gradio**    | ML demos            | Model prototyping, Research demos |
| **Streamlit** | Data applications   | Analytics dashboards, BI tools    |

## Getting Started

::alert{color="green" icon="i-heroicons-rocket-launch"}
**Ready to start building?** Choose your framework and begin with the appropriate prompt templates. Remember to adapt these examples to your specific project needs.
::

### Quick Start Checklist

::list{icon="i-heroicons-check"}
- Identify your project requirements and constraints
- Choose the appropriate framework for your use case
- Start with a basic project setup prompt
- Iterate with specific feature implementation prompts
- Apply best practices for code quality and security
- Set up proper testing and deployment workflows
::

::card
---
color: blue
icon: i-heroicons-chat-bubble-left-right
title: Need Help?
---
These prompts are starting points. Feel free to modify them based on your specific requirements, and don't hesitate to break complex tasks into smaller, more manageable prompts.

**Pro Tip:** Combine multiple prompts for complex applications, building one feature at a time.
::


# Introduction

![CodinIT Platform](https://codinit.dev/opengraph.png){style="border-radius: 12px; max-width: 100%;"}

## Platform Capabilities

The platform provides all the tools you need to create amazing websites, front-end applications as well as full-stack web applications from one browser tab - no installation required. CodinIT includes AI coding tools, real-time collaboration, and project sharing to give you a head start on your app creation journey.

| Capability       | Description                                 | Maturity Level |
| ---------------- | ------------------------------------------- | -------------- |
| Frontend / UI    | Build user interfaces & frontend            | üü¢ Mature      |
| Persistence      | Store and retrieve data                     | üü¢ Mature      |
| Authentication   | Handle user login and accounts              | üü¢ Mature      |
| Backend endpoint | API key protected endpoint such as OpenAI   | üü¢ Mature      |
| Deployment       | Publish, custom domains & deploy            | üü¢ Mature      |
| Collaboration    | Collaborate with other users within project | üü¢ Mature      |
| Real-time sync   | Sync data across users in real-time         | üü¢ Mature      |

## Quick Start Journey

To create your app on CodinIT, choose the guide that matches your needs:

::steps{level="3"}
### Tutorial

Step-by-step tutorial for a simple introduction to key features and concepts.

### Integrations

Go beyond default features by integrating with third parties like Supabase, Stripe or others.

### Prompt Engineering

Learn effective prompting strategies and get the most out of CodinIT.

### Custom Domain

Add your own domain to any CodinIT site app.

### Deploy

Learn how to deploy, share, and get traffic to your web applications with CodinIT.
::

## What is CodinIT

::callout{color="primary"}
**Letting Ordinary Visionaries Achieve Breakthroughs with Language-based Engineering.**

CodinIT is an AI-powered platform that lets you create and deploy apps from a single browser tab. The platform eliminates the complexity of traditional app-creation environments by combining coding, deployment, and collaboration tools in a single interface.
::

Typically, you must install programs, languages, and packages to build apps. However, on CodinIT, you can rely on AI to configure your environment so you can start building without coding experience.

The platform supports full-featured development and coding environments for those familiar with coding as well as those who are not, so there's no limit on what's possible.

### Key Features

- **Complete app generation** and setup from natural language description
- **Code suggestions** and autocomplete with AI assistance
- **Automated error detection** and debugging assistance
- **Documentation generation** for your applications
- **App deployment** to the cloud in a few clicks
- **Database integration** and hosting with Supabase native integration
- **Custom domain support** and connection

Your development environment structure will look like this:

```text
codinit-project/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îî‚îÄ‚îÄ config.json
```

## Essential Resources

::card-group
  :::card
  ---
  ariaLabel: Browse and use project templates
  icon: i-lucide-folder-open
  title: Templates
  ---
  Browse and use project templates to quickly start your next project.
  :::

  :::card
  ---
  ariaLabel: Get a full overview of how to build an app with CodinIT
  icon: i-lucide-play-circle
  title: Tutorial
  ---
  Get a full overview of how to build an app with CodinIT.
  :::

  :::card
  ---
  ariaLabel: Resolve issues in your development lifecycle
  icon: i-lucide-wrench
  title: Troubleshooting
  ---
  Resolve issues in your development lifecycle.
  :::

  :::card
  ---
  ariaLabel: Getting the Most Out of CodinIT
  icon: i-lucide-star
  title: Best Practices
  ---
  Getting the Most Out of CodinIT.
  :::

  :::card
  ---
  ariaLabel: Collaborate on your app in real time with teammates
  icon: i-lucide-users
  title: Teams
  ---
  Collaborate on your app in real time with teammates.
  :::
::

## Stay Connected

### Community & Support

::card-group
  :::card
  ---
  ariaLabel: Share ideas and let the community vote
  icon: i-lucide-lightbulb
  title: Feature Requests
  ---
  Have an idea? Share it and let the community vote
  :::

  :::card
  ---
  ariaLabel: Get help from our Community and Community Champions
  icon: i-lucide-help-circle
  title: Community Support
  ---
  Get help from our Community and Community Champions
  :::

  :::card{ariaLabel="Report a bug or an issue" icon="i-lucide-bug" title="Issues"}
  Found a bug or an issue? Let us know
  :::

  :::card
  ---
  ariaLabel: Direct support channel for paying users
  icon: i-lucide-headphones
  title: Priority Support
  ---
  Direct support channel for paying users
  :::
::

### Programs & Partnerships

::card-group
  :::card
  ---
  ariaLabel: Publish your app to get in front of thousands of people
  icon: i-lucide-rocket
  title: Launched
  ---
  Publish your app to get in front of thousands of people
  :::

  :::card
  ---
  ariaLabel: Join as an expert, or get help from our network of experts
  icon: i-lucide-handshake
  title: Partner Program
  ---
  Join as an expert, or get help from our network of experts
  :::

  :::card
  ---
  ariaLabel: Receive a 20% commission on the first 12 payments
  icon: i-lucide-percent
  title: Affiliate Program
  ---
  Receive a 20% commission on the first 12 payments
  :::
::

### Learn More about CodinIT

::card-group
  :::card
  ---
  ariaLabel: Learn more about CodinIT on our website
  icon: i-lucide-globe
  title: Visit our Website
  to: https://codinit.dev
  ---
  Explore our official website to learn more about CodinIT.
  :::

  :::card
  ---
  ariaLabel: Understand key development terms in our documentation
  icon: i-lucide-book-open
  title: Learn More
  to: https://docs.codinit.dev/getting-started/quickstart
  ---
  Familiarize yourself with key development terms by exploring our Documentation.
  :::

  :::card
  ---
  ariaLabel: prompting with codinit
  icon: i-lucide-briefcase
  title: Find out how to prompt with codinit
  to: https://codinit.dev/blog/prompting-with-codinit
  ---
  Learn how to prompt codinit for best results.
  :::

  :::card
  ---
  ariaLabel: Stay updated with the latest from the CodinIT team
  icon: i-lucide-megaphone
  title: Read Our Blog Announcements
  to: https://codinit.dev/blog
  ---
  Catch up on the latest news and updates from the CodinIT team.
  :::
::

::tip
üéâ Ready to start building? Choose your path from the Quick Start section above and begin creating your next application with CodinIT!
::


# Quickstart

Get your first CodinIT application running in under 10 minutes with this comprehensive quickstart guide.

::alert{color="green" icon="i-lucide-rocket"}
**New to CodinIT?** This guide walks you through the complete workflow from project creation to deployment.
::

## Create Your First Project

::steps{level="4"}
#### Step 1: Start a New Project

Navigate to your CodinIT dashboard and click **"Create New Project"**. Choose from:

- üì± **Mobile App** ‚Äì Responsive mobile-first applications
- üåê **Web Application** ‚Äì Full-stack web apps with backend
- üé® **Landing Page** ‚Äì Marketing sites and portfolios
- üìä **Dashboard** ‚Äì Data visualization and admin panels

#### Step 2: Describe Your App

Use natural language to describe what you want to build:

```text
Create a task management app with user authentication, 
the ability to add, edit, and delete tasks, and a 
dashboard showing task statistics.
```

#### Step 3: Review Generated Code

CodinIT will generate your complete application. Review the:

- Frontend components and styling
- Backend API endpoints
- Database schema and models
- Authentication setup

#### Step 4: Customize and Iterate

Make changes using natural language prompts or direct code editing:

```text
Add a priority system to tasks with high, medium, low options.
Style the app with a dark theme and modern card layout.
```
::

## Essential Editing Features

::card-group
  :::card{icon="i-lucide-edit" title="AI-Powered Editing"}
  Make changes using natural language prompts with instant preview
  :::

  :::card{icon="i-lucide-eye" title="Visual Editor"}
  Click and edit components directly with AI-driven visual controls
  :::

  :::card{icon="i-lucide-undo" title="Version Control"}
  Restore past versions instantly and bookmark important milestones
  :::

  :::card{icon="i-lucide-sparkles" title="Smart Suggestions"}
  Get AI suggestions for improvements and feature additions
  :::

  :::card{icon="i-lucide-image-plus" title="Media Integration"}
  Attach images and files directly to prompts for better context
  :::

  :::card{icon="i-lucide-layers" title="Component Library"}
  Access pre-built components and templates for faster development
  :::
::

## Knowledge Base Setup

Organize your project information for better AI assistance:

::steps{level="4"}
#### Step 1: Access Knowledge Base

Go to the Knowledge Base section in your dashboard.

#### Step 2: Add Project Documentation

Click "Add Entry" and categorize information under:

- üìå **Project Overview** ‚Äì Define objectives and scope
- üöÄ **Key Features** ‚Äì List core functionalities
- üé® **Design Guidelines** ‚Äì Document UI/UX principles
- üîß **Technical Requirements** ‚Äì Specify technologies and constraints

#### Step 3: Keep Information Current

Regularly review and update entries as your project evolves to ensure development stays aligned with your vision.
::

## Add Backend Capabilities

### Connect with Supabase

Supabase integration provides powerful backend capabilities with minimal setup:

::steps{level="4"}
#### Step 1: Create Supabase Project

Create an account on [Supabase](https://supabase.com){ariaLabel="Supabase Website" rel="nofollow"} and set up a new project.

#### Step 2: Link to CodinIT

In CodinIT, navigate to Settings ‚Üí Connect Supabase and follow the integration steps.

#### Step 3: Configure Data Models

Set up database tables, manage user data, and configure real-time subscriptions.

#### Step 4: Enable Authentication

Configure user authentication flows including email verification and social logins.
::

### Authentication Implementation

::tabs
  :::div{label="Setup Process"}
  **Step 1: Supabase Account Creation**
  
  Visit Supabase and sign up to access the project dashboard.
  
  **Step 2: Integration Configuration**
  
  Input your Supabase project URL and API keys to establish connection.
  
  **Step 3: Authentication Forms**
  
  Use CodinIT's AI form builder to create intuitive login and registration forms.
  
  **Step 4: Workflow Implementation**
  
  Set up Supabase Edge Functions for token validation and session management.
  :::

  :::div{label="Advanced Features"}
  **Email Verification**
  
  Configure automated email verification upon user registration.
  
  **Social Authentication**
  
  Enable Google, GitHub, and other OAuth provider integrations.
  
  **Role-Based Access**
  
  Implement user roles and permissions for secure access control.
  
  **Session Management**
  
  Handle user sessions with automatic refresh and secure logout.
  :::
::

## Testing and Deployment

### Preview Your Application

::alert{color="blue" icon="i-lucide-monitor"}
**Live Preview** - Every change is instantly reflected in the preview pane, allowing you to test functionality in real-time.
::

- **Responsive Testing** ‚Äì Check how your app looks on different device sizes
- **Feature Testing** ‚Äì Test user flows and interactions
- **Performance Monitoring** ‚Äì Monitor loading times and responsiveness

### Deploy to Production

::steps{level="3"}
### Step 1: Pre-Deployment Check

Review your application for:

- Functionality completeness
- Responsive design across devices
- Performance optimization
- Error handling

### Step 2: Choose Deployment Option

Select from multiple deployment options:

- **CodinIT Hosting** ‚Äì Instant deployment with custom domain support
- **GitHub Integration** ‚Äì Deploy via GitHub Pages or other CI/CD platforms
- **Custom Hosting** ‚Äì Export code for deployment anywhere

### Step 3: Configure Custom Domain

Add your custom domain for professional deployment:

- Point your domain to CodinIT's servers
- Configure SSL certificates automatically
- Set up redirect rules and routing
::

## Next Steps

::card-group
  :::card
  ---
  ariaLabel: Learn about team collaboration features
  icon: i-lucide-users
  title: Team Collaboration
  to: https://docs.codinit.dev/getting-started/teams
  ---
  Invite team members and collaborate in real-time
  :::

  :::card
  ---
  ariaLabel: Connect with third-party services and APIs
  icon: i-lucide-puzzle
  title: Integrations
  to: https://docs.codinit.dev/integrations/github
  ---
  Connect with third-party services and APIs
  :::

  :::card
  ---
  ariaLabel: Explore framework-specific development resources
  icon: i-lucide-code
  title: Developer Tools
  to: https://docs.codinit.dev/getting-started/developer-docs
  ---
  Explore framework-specific development resources
  :::
::

::tip
üéâ **Congratulations!** You've completed the quickstart guide. Your application is ready for further development and customization. Explore the advanced features to build even more powerful applications.
::


# Teams

CodinIT lets you build apps together, live. Invite your designer, developer, agency, or anyone else to your workspace. Everyone sees changes as they happen in real-time.

::callout{color="blue" icon="i-lucide-users"}
**Collaborative Development** - Experience seamless team collaboration with real-time editing, shared workspaces, and professional project management tools.
::

## Workspace Plans

Each subscription connects to a workspace with different collaboration capabilities:

::card-group
  :::card{color="primary" icon="i-lucide-user" title="Pro Subscription"}
  Personal workspaces with up to 2 collaborators per project. Collaborators use project owner credits for seamless cost management.
  :::

  :::card{color="green" icon="i-lucide-users" title="Teams Subscription"}
  Up to 20 users in workspace. Owners & admins manage users and projects. Shared credit pool for all team members.
  :::
::

## Workspace Management

### Create a Workspace

A workspace is your shared environment for building and collaborating on projects with your team.

::steps{level="3"}
### Step 1: Create New Workspace

Click **"Create new workspace"** from the dashboard or any existing project.

### Step 2: Name Your Workspace

Choose a descriptive name for your workspace that reflects your team or organization.

### Step 3: Choose a Plan

Select a subscription plan that fits your team size and collaboration requirements.
::

### Rename a Workspace

::steps{level="3"}
### Step 1: Switch to Workspace

Ensure you're in the correct workspace (switch if needed from the sidebar).

### Step 2: Access Settings

Navigate to **Settings** from your workspace dashboard.

### Step 3: Edit Details

Update the **Workspace name** and **description** to reflect changes in your team or project focus.
::

## Team Member Management

### Invite & Manage Collaborators

::steps{level="3"}
### Step 1: Upgrade Your Plan

Upgrade to the **Teams** tier if you're currently on a personal plan.

### Step 2: Send Invitations

Click **"Invite"** in a project or from the main dashboard to access the invitation system.

### Step 3: Add Team Members

Enter email addresses to send invitations to your team members and collaborators.

### Step 4: Team Integration

When invitations are accepted, members join your workspace and gain access to all shared projects.
::

### Role-Based Permissions

Different roles provide varying levels of access and control within your workspace:

| Action                                          | Owner | Admin | Editor |
| ----------------------------------------------- | ----- | ----- | ------ |
| Edit projects                                   | ‚úì     | ‚úì     | ‚úì      |
| Publish projects                                | ‚úì     | ‚úì     | ‚úì      |
| Connect/disconnect Supabase org to workspace    | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect Supabase project to projects | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub org to workspace      | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub repo to projects      | ‚úì     | ‚úì     | ‚úó      |
| Invite project-level collaborators              | ‚úì     | ‚úì     | ‚úó      |
| Transfer projects to other workspaces           | ‚úì     | ‚úì     | ‚úó      |
| Set roles for other users                       | ‚úì     | ‚úì     | ‚úó      |

### Role Descriptions

::field-group
  :::field{name="Owner" type="role"}
  Complete administrative control over the workspace, billing management, and all projects
  :::

  :::field{name="Admin" type="role"}
  Can manage most workspace and project aspects, but cannot modify other admin roles
  :::

  :::field{name="Editor" type="role"}
  Can edit and publish projects but cannot manage workspace settings, integrations, or user permissions
  :::
::

## Real-Time Collaboration Features

Once team members join your workspace, experience seamless real-time collaboration:

::card-group
  :::card
  ---
  ariaLabel: See team member cursors and live changes in real-time
  icon: i-lucide-mouse-pointer
  title: Live Cursors
  ---
  See team member cursors and live changes as they work in real-time
  :::

  :::card
  ---
  ariaLabel: Icons show who's currently online and active
  icon: i-lucide-circle-dot
  title: Team Presence
  ---
  Icons in top-right corner show who's currently online and active
  :::

  :::card
  ---
  ariaLabel: Edit any element together with immediate synchronization
  icon: i-lucide-edit
  title: Instant Editing
  ---
  Edit any element together with immediate synchronization across all users
  :::

  :::card
  ---
  ariaLabel: All modifications reflected immediately across all team members' screens
  icon: i-lucide-refresh-cw
  title: Change Synchronization
  ---
  All modifications reflected immediately across all team members' screens
  :::
::


# Developer Docs

Framework-focused prompting strategies and development patterns for building applications with CodinIT. Each section provides proven patterns, best practices, and ready-to-use prompts tailored to specific technology stacks.

::callout{color="blue" icon="i-heroicons-code-bracket"}
**Framework-Focused Prompts** - Specialized prompt patterns for Next.js, Python, Gradio, and Streamlit development. Copy, modify, and use these templates to build better applications faster.
::

## Overview

This library provides targeted prompting strategies for specific development frameworks. Each section contains proven patterns, best practices, and ready-to-use prompts tailored to the unique characteristics of each technology stack.

::alert{color="green" icon="i-heroicons-light-bulb"}
**Pro Tip** - These prompts are designed to work with any AI coding assistant. Adapt the examples to your specific project needs and requirements.
::

## Supported Frameworks

::card-group{cols="2"}
  :::card
  ---
  ariaLabel: Learn about Next.js Development
  icon: i-simple-icons-nextdotjs
  title: Next.js Development
  ---
  Full-stack React framework with SSR, API routes, and modern tooling for web applications.
  
  :badge[React]{color="blue" variant="outline"} :badge[TypeScript]{color="blue" variant="outline"} :badge[Full-Stack]{color="green" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Python Development
  icon: i-simple-icons-python
  title: Python Development
  ---
  Backend services, data processing, and general-purpose application development.
  
  :badge[Backend]{color="orange" variant="outline"} :badge[Data Science]{color="purple" variant="outline"} :badge[APIs]{color="emerald" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Gradio Development
  icon: i-heroicons-chart-bar
  title: Gradio Development
  ---
  Rapid ML model deployment and interactive data science applications.
  
  :badge[ML/AI]{color="red" variant="outline"} :badge[Interactive]{color="cyan" variant="outline"} :badge[Prototyping]{color="amber" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Streamlit Development
  icon: i-heroicons-presentation-chart-line
  title: Streamlit Development
  ---
  Data apps and dashboards with Python-first development approach.
  
  :badge[Data Apps]{color="indigo" variant="outline"} :badge[Dashboards]{color="pink" variant="outline"} :badge[Analytics]{color="teal" variant="outline"}
  :::
::

---

## Next.js Development

::callout{color="black" icon="i-simple-icons-nextdotjs"}
**Modern React framework with server-side rendering, API routes, and performance optimization.**
::

### Project Setup & Architecture

::tabs
  :::div{label="New Project Setup"}
  ```markdown
  Create a new Next.js 14 application with the following specifications:
  
  **Tech Stack:**
  - Next.js 14 with App Router
  - TypeScript for type safety
  - Tailwind CSS for styling
  - Prisma with PostgreSQL for database
  - NextAuth.js for authentication
  
  **Project Structure:**
  - `/app` directory structure with proper layouts
  - `/components` for reusable UI components
  - `/lib` for utilities and database configuration
  - `/types` for TypeScript definitions
  
  **Initial Features:**
  - Landing page with hero section and navigation
  - User authentication (sign up, login, logout)
  - Protected dashboard route
  - Responsive design with dark mode support
  
  Set up the basic project structure and create placeholder components.
  ```
  :::

  :::div{label="Component Architecture"}
  ```markdown
  Design a component architecture for a [describe app type] application:
  
  **Component Categories:**
  - UI components (buttons, inputs, cards)
  - Layout components (header, sidebar, footer)
  - Feature components (user profile, product listing)
  - Page components (home, dashboard, settings)
  
  **Requirements:**
  - TypeScript interfaces for all props
  - Compound component patterns where appropriate
  - Accessibility features (ARIA labels, keyboard navigation)
  - Consistent styling with Tailwind CSS variants
  
  Include examples of 2-3 components with proper TypeScript typing.
  ```
  :::
::

---

## Python Development

::callout{color="yellow" icon="i-simple-icons-python"}
**Versatile language for backend development, data processing, and API creation.**
::

### API Development

::tabs
  :::div{label="FastAPI Setup"}
  ```markdown
  Create a FastAPI application with the following requirements:
  
  **Features:**
  - RESTful API with CRUD operations
  - User authentication with JWT tokens
  - Database integration with SQLAlchemy
  - Input validation with Pydantic
  - Automated API documentation
  
  **Structure:**
  - `/models` for database models
  - `/routers` for API endpoints
  - `/schemas` for Pydantic models
  - `/auth` for authentication logic
  
  Include user registration, login, and protected endpoints.
  ```
  :::

  :::div{label="Data Processing"}
  ```markdown
  Build a data processing pipeline that:
  
  **Input Sources:**
  - CSV files from uploads
  - Database queries
  - API endpoints
  
  **Processing Steps:**
  - Data cleaning and validation
  - Statistical analysis
  - Visualization generation
  - Export to multiple formats
  
  **Output:**
  - Processed datasets
  - Summary statistics
  - Interactive charts
  - Automated reports
  
  Use pandas, numpy, and plotly for implementation.
  ```
  :::
::

---

## Gradio Development

::callout{color="red" icon="i-heroicons-chart-bar"}
**Rapid prototyping framework for ML models and interactive demos.**
::

### Interactive ML Applications

::tabs
  :::div{label="Model Demo Interface"}
  ```markdown
  Create a Gradio interface for [ML model type]:
  
  **Interface Components:**
  - File upload for input data
  - Parameter sliders for model tuning
  - Real-time prediction display
  - Confidence scores and explanations
  - Download results functionality
  
  **Features:**
  - Batch processing capabilities
  - Model comparison tools
  - Performance metrics display
  - Error handling and validation
  
  Include examples with sample data and clear instructions.
  ```
  :::

  :::div{label="Data Visualization Dashboard"}
  ```markdown
  Build a Gradio dashboard for data exploration:
  
  **Components:**
  - Dataset upload and preview
  - Interactive charts and plots
  - Statistical summary tables
  - Filter and search capabilities
  - Export functionality
  
  **Visualizations:**
  - Distribution plots
  - Correlation matrices
  - Time series analysis
  - Geographic mapping (if applicable)
  
  Make it responsive and user-friendly for non-technical users.
  ```
  :::
::

---

## Streamlit Development

::callout{color="red" icon="i-heroicons-presentation-chart-line"}
**Python-first framework for building data applications and interactive dashboards.**
::

### Data Dashboards

::tabs
  :::div{label="Analytics Dashboard"}
  ```markdown
  Create a comprehensive analytics dashboard using Streamlit:
  
  **Data Sources:**
  - Multiple data source connections (CSV, database, API)
  - Real-time data refresh capabilities
  - Data caching for performance
  - Error handling for data loading
  
  **Dashboard Layout:**
  - Multi-page application structure
  - Sidebar navigation and filters
  - Responsive grid layout
  - Customizable date ranges
  - Export functionality
  
  **Visualizations:**
  - KPI metrics with st.metric()
  - Interactive charts with Plotly
  - Data tables with filtering/sorting
  - Geographic visualizations
  
  Include caching and performance optimization.
  ```
  :::

  :::div{label="Machine Learning App"}
  ```markdown
  Build a complete ML application with Streamlit:
  
  **Features:**
  - Model training interface
  - Hyperparameter tuning
  - Performance evaluation
  - Prediction interface
  - Model deployment options
  
  **Components:**
  - Data upload and preprocessing
  - Model selection and training
  - Results visualization
  - Model comparison tools
  - Export trained models
  
  Include proper error handling and user guidance.
  ```
  :::
::

---

## Development Best Practices

::alert{color="amber" icon="i-heroicons-star"}
**Quality Assurance** - Follow these practices for professional-grade applications regardless of framework choice.
::

### Code Quality Guidelines

::steps{level="4"}
#### Step 1: Planning & Design

Start with clear requirements and architecture design before implementation.

#### Step 2: Iterative Development

Build features incrementally with regular testing and validation.

#### Step 3: Code Review

Implement peer review processes for maintaining code quality standards.

#### Step 4: Deployment & Monitoring

Set up automated deployment with proper monitoring and error tracking.
::

### Framework Selection Guide

Choose the right framework based on your project requirements:

| Framework     | Best For            | Use Cases                         |
| ------------- | ------------------- | --------------------------------- |
| **Next.js**   | Full-stack web apps | E-commerce, SaaS, Marketing sites |
| **Python**    | Backend services    | APIs, Data processing, Automation |
| **Gradio**    | ML demos            | Model prototyping, Research demos |
| **Streamlit** | Data applications   | Analytics dashboards, BI tools    |

## Getting Started

::alert{color="green" icon="i-heroicons-rocket-launch"}
**Ready to start building?** Choose your framework and begin with the appropriate prompt templates. Remember to adapt these examples to your specific project needs.
::

### Quick Start Checklist

::list{icon="i-heroicons-check"}
- Identify your project requirements and constraints
- Choose the appropriate framework for your use case
- Start with a basic project setup prompt
- Iterate with specific feature implementation prompts
- Apply best practices for code quality and security
- Set up proper testing and deployment workflows
::

::card
---
color: blue
icon: i-heroicons-chat-bubble-left-right
title: Need Help?
---
These prompts are starting points. Feel free to modify them based on your specific requirements, and don't hesitate to break complex tasks into smaller, more manageable prompts.

**Pro Tip:** Combine multiple prompts for complex applications, building one feature at a time.
::


# GitHub

Import your existing GitHub repositories into CodinIT to leverage AI-powered development on your current codebase.

::callout{icon="i-simple-icons-github"}
**Import Existing Code:** Connect your GitHub repositories to CodinIT for AI-enhanced development of existing projects.
::

## Why Import GitHub Repositories?

::card-group
  :::card{icon="i-lucide-code" title="Leverage Existing Code"}
  Build upon your existing codebase with AI assistance instead of starting from scratch.
  :::

  :::card{icon="i-lucide-zap" title="Modernize Legacy Apps"}
  Add new features to older projects using modern AI development techniques.
  :::

  :::card{icon="i-lucide-users" title="Team Transition"}
  Gradually migrate team workflows to AI-assisted development.
  :::

  :::card{icon="i-lucide-git-branch" title="Maintain History"}
  Preserve complete git history while adding AI development capabilities.
  :::
::

## Supported Repository Types

CodinIT can import and enhance various types of GitHub repositories:

::tabs
  :::div{label="Web Applications"}
  **Frontend and full-stack applications:**
  
  - **React/Next.js** - Add new components and features with AI assistance.
  - **Vue/Nuxt** - Enhance existing applications with AI-generated code.
  - **Angular** - Modernize components and add intelligent features.
  - **Vanilla JavaScript** - Upgrade to modern frameworks with AI guidance.
  :::

  :::div{label="Backend Services"}
  **APIs and server applications:**
  
  - **Node.js/Express** - Add new endpoints and business logic.
  - **Python/Django** - Enhance data processing and API capabilities.
  - **PHP/Laravel** - Modernize legacy PHP applications.
  - **Ruby/Rails** - Add new features to existing Rails apps.
  :::

  :::div{label="Data & Analytics"}
  **Data processing and analysis projects:**
  
  - **Python Data Science** - Enhance analysis with AI-generated insights.
  - **Jupyter Notebooks** - Add interactive features and visualizations.
  - **R Projects** - Integrate modern web interfaces.
  - **SQL Databases** - Generate query optimization and reporting features.
  :::
::

## Repository Import Process

::steps
### Connect GitHub Account

Authorize CodinIT to access your GitHub repositories in your settings.

### Choose Repository to Import

Select the public or private GitHub repository you want to enhance with AI development.

### Configure AI Model

Choose the AI provider that best fits your project needs.

### Import and Analyze

CodinIT will analyze your codebase and prepare it for AI-enhanced development.
::

## Post-Import Development

Once imported, use AI to understand your codebase, add new features, and modernize your application.

::collapsible{title="Feature Enhancement Examples"}
**Add Authentication to Existing App:**

```text
Add user authentication to this application:
- User registration and login pages
- Protected routes and middleware
- Session management
- Password reset functionality
- Integration with existing database schema
```

**Modernize UI Components:**

```text
Modernize the user interface:
- Convert existing components to modern design system
- Add responsive design for mobile compatibility
- Implement dark mode support
- Improve accessibility features
```

**Add API Endpoints:**

```text
Add new API functionality:
- RESTful endpoints for data management
- Input validation and error handling
- Database integration with existing schema
- API documentation and testing
```
::

## Best Practices for Repository Import

### Pre-Import Preparation

::checklist
- Clean up unused files and dependencies.
- Ensure repository has clear folder structure.
- Add basic README with project description.
- Remove sensitive data and API keys.
- Create main branch with stable code.
::

### Post-Import Optimization

::tabs
  :::div{label="Code Organization"}
  **Organize code for better AI understanding:**
  
  - Use descriptive file and folder names.
  - Add comments explaining complex business logic.
  - Separate concerns into logical modules.
  - Maintain consistent coding style throughout.
  :::

  :::div{label="AI Prompting"}
  **Write effective prompts for existing codebases:**
  
  - Reference specific files and functions in prompts.
  - Explain existing patterns to maintain consistency.
  - Ask for incremental improvements rather than rewrites.
  - Use AI to understand code before making changes.
  :::
::


# Plugins

Connect CodinIT with your favorite tools and services to build production-ready applications faster. From version control to databases, deployment platforms, and AI providers.

::callout{icon="i-heroicons-information-circle"}
**Integration Philosophy:** CodinIT.dev is designed to work with your existing development ecosystem, not replace it. These integrations ensure you maintain full control over your codebase while leveraging AI-powered development tools.
::

## Database Integrations

::tabs
  :::div{label="SQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-postgresql" title="PostgreSQL"}
      Industry-standard relational database with advanced features, JSON support, and excellent performance.
      :::::
    
      :::::card{icon="i-simple-icons-mysql" title="MySQL"}
      Popular open-source relational database known for reliability and ease of use.
      :::::
    
      :::::card{icon="i-simple-icons-sqlite" title="SQLite"}
      Lightweight, file-based SQL database perfect for development and small applications.
      :::::
    
      :::::card{icon="i-lucide-database" title="Microsoft SQL Server"}
      Enterprise-grade database with advanced analytics and business intelligence features.
      :::::
    ::::
  :::

  :::div{label="NoSQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-mongodb" title="MongoDB"}
      Document-oriented database with flexible schema and horizontal scaling capabilities.
      :::::
    
      :::::card{icon="i-simple-icons-redis" title="Redis"}
      In-memory data structure store used as database, cache, and message broker.
      :::::
    
      :::::card{icon="i-lucide-database" title="CouchDB"}
      Document database with multi-master replication and web-based administration.
      :::::
    
      :::::card{icon="i-lucide-layers" title="DynamoDB"}
      Amazon's managed NoSQL database service with automatic scaling and high availability.
      :::::
    ::::
  :::

  :::div{label="Cloud Database Services"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-supabase" title="Supabase"}
      Open-source Firebase alternative with PostgreSQL, real-time subscriptions, and built-in authentication.
      :::::
    
      :::::card{icon="i-simple-icons-firebase" title="Firebase"}
      Google's mobile and web application development platform with real-time database and hosting.
      :::::
    
      :::::card{icon="i-simple-icons-planetscale" title="PlanetScale"}
      Serverless MySQL platform with branching, schema migrations, and automatic scaling.
      :::::
    
      :::::card{icon="i-lucide-database" title="Neon"}
      Serverless PostgreSQL with automatic scaling, branching, and point-in-time recovery.
      :::::
    ::::
  :::
::

## AI Model Providers

::card-group{cols="2"}
  :::card{icon="i-lucide-brain" title="Anthropic Claude"}
  Advanced reasoning capabilities with Claude 4 Sonnet and other models for sophisticated code generation and problem-solving.
  :::

  :::card{icon="i-lucide-bot" title="OpenAI GPT"}
  Industry-leading language models including GPT-4, GPT-4 Turbo, and o1 for intelligent app development.
  :::

  :::card{icon="i-lucide-sparkles" title="Google Gemini"}
  Google's multimodal AI with Gemini Pro and Flash models for fast and efficient development.
  :::

  :::card{icon="i-lucide-server" title="Local Models (Ollama)"}
  Run AI models locally for privacy, offline development, and cost control.
  :::
::

## Deployment Platforms

::card-group{cols="2"}
  :::card{icon="i-simple-icons-vercel" title="Vercel"}
  Optimized for modern frontend frameworks with automatic deployments and edge computing.
  :::

  :::card{icon="i-simple-icons-netlify" title="Netlify"}
  All-in-one platform for web projects with forms, functions, and identity management.
  :::

  :::card{icon="i-simple-icons-amazonaws" title="AWS"}
  Comprehensive cloud platform with extensive services for any application size.
  :::

  :::card{icon="i-simple-icons-googlecloud" title="Google Cloud"}
  Google's cloud platform with AI/ML services and global infrastructure.
  :::
::

## Authentication & Security

::card-group{cols="2"}
  :::card{icon="i-simple-icons-auth0" title="Auth0"}
  Enterprise identity platform with social logins, multi-factor authentication, and compliance features.
  :::

  :::card{icon="i-simple-icons-firebase" title="Firebase Auth"}
  Google's authentication service with social providers and email/password authentication.
  :::

  :::card{icon="i-simple-icons-supabase" title="Supabase Auth"}
  Open-source authentication with built-in database integration and social providers.
  :::

  :::card{icon="i-lucide-key" title="NextAuth.js"}
  Open-source authentication library for Next.js applications with multiple provider support.
  :::
::

## Payment Processing

::card-group{cols="2"}
  :::card{icon="i-simple-icons-stripe" title="Stripe"}
  Industry-leading payment platform with comprehensive APIs and global coverage.
  :::

  :::card{icon="i-simple-icons-paypal" title="PayPal"}
  Global payment platform with buyer protection and multiple payment methods.
  :::
::

## Communication & Notifications

::card-group{cols="2"}
  :::card{icon="i-lucide-mail" title="Resend"}
  Developer-first email API with excellent deliverability and React email templates.
  :::

  :::card{icon="i-simple-icons-mailgun" title="Mailgun"}
  Powerful email API for developers with advanced routing and analytics.
  :::
::

## Analytics & Monitoring

::card-group{cols="2"}
  :::card{icon="i-simple-icons-googleanalytics" title="Google Analytics"}
  Comprehensive web analytics platform with audience insights and conversion tracking.
  :::

  :::card{icon="i-lucide-activity" title="Umami"}
  Privacy-focused, open-source web analytics alternative to Google Analytics.
  :::
::


# Anthropic

> Learn how to configure and use Anthropic Claude models with CodinIT.dev. Covers API key setup, model selection, and advanced features like prompt caching.

**Website:** <https://www.anthropic.com/>{ariaLabel="Anthropic Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [Anthropic Console](https://console.anthropic.com/){ariaLabel="Anthropic Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the [API keys](https://console.anthropic.com/settings/keys){ariaLabel="Anthropic API Keys Settings" rel="nofollow"} section.
3. **Create a Key:** Click "Create Key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following Anthropic Claude models:

- `claude-opus-4-20250514`
- `claude-opus-4-20250514:thinking` (Extended Thinking variant)
- `claude-sonnet-4-20250514` (Recommended)
- `claude-sonnet-4-20250514:thinking` (Extended Thinking variant)
- `claude-3-7-sonnet-20250219`
- `claude-3-7-sonnet-20250219:thinking` (Extended Thinking variant)
- `claude-3-5-sonnet-20241022`
- `claude-3-5-haiku-20241022`
- `claude-3-opus-20240229`
- `claude-3-haiku-20240307`

See [Anthropic's Model Documentation](https://docs.anthropic.com/en/docs/about-claude/models){ariaLabel="Anthropic Model Documentation" rel="nofollow"} for more details on each model's capabilities.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "Anthropic" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your Anthropic API key into the "Anthropic API Key" field.
4. **Select Model:** Choose your desired Claude model from the "Model" dropdown.
5. **(Optional) Custom Base URL:** If you need to use a custom base URL for the Anthropic API, check "Use custom base URL" and enter the URL. Most users won't need to adjust this setting.

### Extended Thinking

Anthropic models offer an "Extended Thinking" feature, designed to give them enhanced reasoning capabilities for complex tasks. This feature allows the model to output its step-by-step thought process before delivering a final answer, providing transparency and enabling more thorough analysis for challenging prompts.

When extended thinking is in CodinIT.dev, the model generates `thinking` content blocks that detail its internal reasoning. These insights are then incorporated into its final response.
CodinIT.dev users can leverage this by checking the `Enable Extended Thinking` box below the model selection menu after selecting a Claude Model from any provider.

**Key Aspects of Extended Thinking:**

- **Supported Models:** This feature is available for select models, including variants of Claude Opus 4, Claude Sonnet 4, and Claude Sonnet 3.7. The specific models listed in the "Supported Models" section above with the `:thinking` suffix are pre-configured in CodinIT.dev to utilize this.
- **Summarized Thinking (Claude 4):** For Claude 4 models, the API returns a summary of the full thinking process to balance insight with efficiency and prevent misuse. You are billed for the full thinking tokens, not just the summary.
- **Streaming:** Extended thinking responses, including the `thinking` blocks, can be streamed.
- **Tool Use & Prompt Caching:** Extended thinking interacts with tool use (requiring thinking blocks to be passed back) and prompt caching (with specific behaviors around cache invalidation and context).

For comprehensive details on how extended thinking works, including API examples, interaction with tool use, prompt caching, and pricing, please refer to the [official Anthropic documentation on Extended Thinking](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking){ariaLabel="Anthropic Extended Thinking Documentation" rel="nofollow"}.

### Tips and Notes

- **Prompt Caching:** Claude 3 models support [prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching){ariaLabel="Anthropic Prompt Caching Documentation" rel="nofollow"}, which can significantly reduce costs and latency for repeated prompts.
- **Context Window:** Claude models have large context windows (200,000 tokens), allowing you to include a significant amount of code and context in your prompts.
- **Pricing:** Refer to the [Anthropic Pricing](https://www.anthropic.com/pricing){ariaLabel="Anthropic Pricing Page" rel="nofollow"} page for the latest pricing information.
- **Rate Limits:** Anthropic has strict rate limits based on [usage tiers](https://docs.anthropic.com/en/api/rate-limits#requirements-to-advance-tier){ariaLabel="Anthropic API Rate Limits Documentation" rel="nofollow"}.


# DeepSeek

> Learn how to configure and use DeepSeek models like deepseek-chat and deepseek-reasoner with CodinIT.dev.

CodinIT.dev supports accessing models through the DeepSeek API, including `deepseek-chat` and `deepseek-reasoner`.

**Website:** <https://platform.deepseek.com/>{ariaLabel="DeepSeek Platform Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [DeepSeek Platform](https://platform.deepseek.com/){ariaLabel="DeepSeek Platform" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Find your API keys in the [API keys](https://platform.deepseek.com/api_keys){ariaLabel="DeepSeek API Keys Section" rel="nofollow"} section of the platform.
3. **Create a Key:** Click "Create new API key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following DeepSeek models:

- `deepseek-v3-0324` (Recommended for coding tasks)
- `deepseek-r1` (Recommended for reasoning tasks)

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the ‚öôÔ∏è icon in the CodinIT.dev panel.
2. **Select Provider:** Choose "DeepSeek" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your DeepSeek API key into the "DeepSeek API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown.

### Tips and Notes

- **Pricing:** Refer to the [DeepSeek Pricing](https://api-docs.deepseek.com/quick_start/pricing/){ariaLabel="DeepSeek Pricing Page" rel="nofollow"} page for details on model costs.


# Google Gemini

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){ariaLabel="Learn more about GCP Vertex AI" rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){ariaLabel="Google Cloud Console" rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){ariaLabel="GCP Vertex AI Access Control documentation" rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){ariaLabel="Download Visual Studio Code" rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){ariaLabel="Google Cloud CLI installation guide" rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){ariaLabel="GCP IAM Best Practices" rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics suchs as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){ariaLabel="Learn more about GCP Vertex AI Quotas" rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){ariaLabel="GCP Vertex AI Documentation" rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# xAI Groq

> Learn how to configure and use xAI's Grok models with CodinIT.dev, including API key setup, supported models, and reasoning capabilities.

xAI is the company behind Grok, a large language model known for its conversational abilities and large context window. Grok models are designed to provide helpful, informative, and contextually relevant responses.

**Website:** <https://x.ai/>{ariaLabel="xAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [xAI Console](https://console.x.ai/){ariaLabel="xAI Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the API keys section in your dashboard.
3. **Create a Key:** Click to create a new API key. Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following xAI Grok models:

#### Grok-3 Models

- `grok-3-beta` (Default) - xAI's Grok-3 beta model with 131K context window
- `grok-3-fast-beta` - xAI's Grok-3 fast beta model with 131K context window
- `grok-3-mini-beta` - xAI's Grok-3 mini beta model with 131K context window
- `grok-3-mini-fast-beta` - xAI's Grok-3 mini fast beta model with 131K context window

#### Grok-2 Models

- `grok-2-latest` - xAI's Grok-2 model - latest version with 131K context window
- `grok-2` - xAI's Grok-2 model with 131K context window
- `grok-2-1212` - xAI's Grok-2 model (version 1212) with 131K context window

#### Grok Vision Models

- `grok-2-vision-latest` - xAI's Grok-2 Vision model - latest version with image support and 32K context window
- `grok-2-vision` - xAI's Grok-2 Vision model with image support and 32K context window
- `grok-2-vision-1212` - xAI's Grok-2 Vision model (version 1212) with image support and 32K context window
- `grok-vision-beta` - xAI's Grok Vision Beta model with image support and 8K context window

#### Legacy Models

- `grok-beta` - xAI's Grok Beta model (legacy) with 131K context window

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "xAI" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your xAI API key into the "xAI API Key" field.
4. **Select Model:** Choose your desired Grok model from the "Model" dropdown.

### Reasoning Capabilities

Grok 3 Mini models feature specialized reasoning capabilities, allowing them to "think before responding" - particularly useful for complex problem-solving tasks.

#### Reasoning-Enabled Models

Reasoning is only supported by:

- `grok-3-mini-beta`
- `grok-3-mini-fast-beta`

The Grok 3 models `grok-3-beta` and `grok-3-fast-beta` do not support reasoning.

#### Controlling Reasoning Effort

When using reasoning-enabled models, you can control how hard the model thinks with the `reasoning_effort` parameter:

- `low`: Minimal thinking time, using fewer tokens for quick responses
- `high`: Maximum thinking time, leveraging more tokens for complex problems

Choose `low` for simple queries that should complete quickly, and `high` for harder problems where response latency is less important.

#### Key Features

- **Step-by-Step Problem Solving**: The model thinks through problems methodically before delivering an answer
- **Math & Quantitative Strength**: Excels at numerical challenges and logic puzzles
- **Reasoning Trace Access**: The model's thinking process is available via the `reasoning_content` field in the response completion object

### Tips and Notes

- **Context Window:** Most Grok models feature large context windows (up to 131K tokens), allowing you to include substantial amounts of code and context in your prompts.
- **Vision Capabilities:** Select vision-enabled models (`grok-2-vision-latest`, `grok-2-vision`, etc.) when you need to process or analyze images.
- **Pricing:** Pricing varies by model, with input costs ranging from $0.3 to $5.0 per million tokens and output costs from $0.5 to $25.0 per million tokens. Refer to the xAI documentation for the most current pricing information.
- **Performance Tradeoffs:** "Fast" variants typically offer quicker response times but may have higher costs, while "mini" variants are more economical but may have reduced capabilities.


# Mistral

Connect Mistral AI's sophisticated models to CodinIT.dev for precise, efficient app development.

::callout{icon="i-lucide-sparkles"}
**Mistral AI Precision** - Experience French AI excellence with Mistral's models known for precise instruction following, exceptional coding capabilities, and efficient performance.
::

## Why Choose Mistral for Development?

::card-group
  :::card{icon="i-lucide-code" title="Coding Specialist"}
  Codestral model specifically designed for software development tasks.
  :::

  :::card{icon="i-lucide-target" title="Precise Instructions"}
  Exceptional accuracy in following detailed technical specifications.
  :::

  :::card{icon="i-lucide-zap" title="Efficient Performance"}
  High-quality outputs with optimized token usage and speed.
  :::

  :::card{icon="i-lucide-globe" title="Multilingual Excellence"}
  Superior support for multiple programming languages and human languages.
  :::
::

## Available Mistral Models

| Model             | Type    | Strengths           | Best For             | Context |
| ----------------- | ------- | ------------------- | -------------------- | ------- |
| **Mistral Large** | General | Advanced reasoning  | Complex applications | 128k    |
| **Codestral**     | Coding  | Code specialization | Software development | 32k     |
| **Mixtral 8x7b**  | General | High throughput     | High-volume usage    | 32k     |
| **Mistral 7b**    | General | Fast responses      | Quick iterations     | 32k     |

## API Key Setup

::steps
### Create Mistral Account

Visit [Mistral Console](https://console.mistral.ai/){ariaLabel="Mistral Console" rel="nofollow"} and create your developer account.

### Generate API Key

Navigate to the API Keys section and create a new key.

### Secure Key Storage

Store your API key securely in your project's environment variables.
::

## CodinIT Configuration

To configure the Mistral provider in CodinIT, navigate to your project settings, select "Mistral" from the AI Provider dropdown, and enter your API key.

## Development Examples

### Full-Stack Application Development

```typescript
// Example: E-commerce platform with Codestral
const prompt = `
Create a complete e-commerce platform using Next.js and TypeScript:
- Product catalog with search and filtering
- Shopping cart with persistent state
- User authentication and profiles
`;
```

### API Development

```python
# Example: Microservices with FastAPI
prompt = """
Design a microservices architecture for a content management system:
- User service with OAuth integration
- Content service with version control
- Media service with CDN integration
"""
```

## Best Practices

### Prompt Engineering

::card-group
  :::card{icon="i-lucide-list" title="Detailed Specifications"}
  Provide comprehensive requirements and technical constraints.
  :::

  :::card{icon="i-lucide-layers" title="Structured Context"}
  Organize information clearly with priorities and dependencies.
  :::

  :::card{icon="i-lucide-code" title="Code Context"}
  Include relevant existing code patterns and architecture.
  :::

  :::card{icon="i-lucide-refresh-cw" title="Iterative Refinement"}
  Build complex features incrementally with feedback loops.
  :::
::

## Troubleshooting Guide

### Common Issues

::accordion
  :::card{title="API Key Type Mismatch"}
  **Resolution Steps:**
  
  1. Verify you're using the correct API key type for your model.
  2. Use Codestral API key specifically for Codestral model.
  3. Use General API key for other Mistral models.
  :::

  :::card{title="Model Access Denied"}
  **Resolution Steps:**
  
  1. Verify your account has access to the selected model.
  2. Check billing status and account standing.
  3. Ensure API key hasn't expired or been revoked.
  :::
::


# Ollama

CodinIT.dev supports running models locally using Ollama. This approach offers privacy, offline access, and potentially reduced costs. It requires some initial setup and a sufficiently powerful computer. Because of the present state of consumer hardware, it's not recommended to use Ollama with CodinIT.dev as performance will likely be poor for average hardware configurations.

**Website:** <https://ollama.com/>{ariaLabel="Ollama Website" rel="nofollow"}

### Setting up Ollama

1. **Download and Install Ollama:**
   Obtain the Ollama installer for your operating system from the [Ollama website](https://ollama.com/){ariaLabel="Ollama Website" rel="nofollow"} and follow their installation guide. Ensure Ollama is running. You can typically start it with:
   ```bash
   ollama serve
   ```
2. **Download a Model:**
   Ollama supports a wide variety of models. A list of available models can be found on the [Ollama model library](https://ollama.com/library){ariaLabel="Ollama Model Library" rel="nofollow"}. Some models recommended for coding tasks include:
   - `codellama:7b-code` (a good, smaller starting point)
   - `codellama:13b-code` (offers better quality, larger size)
   - `codellama:34b-code` (provides even higher quality, very large)
   - `qwen2.5-coder:32b`
   - `mistralai/Mistral-7B-Instruct-v0.1` (a solid general-purpose model)
   - `deepseek-coder:6.7b-base` (effective for coding)
   - `llama3:8b-instruct-q5_1` (suitable for general tasks)
   :brTo download a model, open your terminal and execute:
   ```bash
   ollama pull <model_name>
   ```
   :brFor instance:
   ```bash
   ollama pull qwen2.5-coder:32b
   ```
3. **Configure the Model's Context Window:**
   By default, Ollama models often use a context window of 2048 tokens, which can be insufficient for many CodinIT.dev requests. A minimum of 12,000 tokens is advisable for decent results, with 32,000 tokens being ideal. To adjust this, you'll modify the model's parameters and save it as a new version. :br First, load the model (using `qwen2.5-coder:32b` as an example):
   ```bash
   ollama run qwen2.5-coder:32b
   ```
   :brOnce the model is loaded within the Ollama interactive session, set the context size parameter:
   ```text
   /set parameter num_ctx 32768
   ```
   :brThen, save this configured model with a new name:
   ```text
   /save your_custom_model_name
   ```
   :br(Replace `your_custom_model_name` with a name of your choice.)
4. **Configure CodinIT.dev:**
   - Open the CodinIT.dev sidebar (usually indicated by the CodinIT.dev icon).
   - Click the settings gear icon (‚öôÔ∏è).
   - Select "ollama" as the API Provider.
   - Enter the Model name you saved in the previous step (e.g., `your_custom_model_name`).
   - (Optional) Adjust the base URL if Ollama is running on a different machine or port. The default is `http://localhost:11434`.
   - (Optional) Configure the Model context size in CodinIT.dev's Advanced settings. This helps CodinIT.dev manage its context window effectively with your customized Ollama model.

### Tips and Notes

- **Resource Demands:** Running large language models locally can be demanding on system resources. Ensure your computer meets the requirements for your chosen model.
- **Model Choice:** Experiment with various models to discover which best fits your specific tasks and preferences.
- **Offline Capability:** After downloading a model, you can use CodinIT.dev with that model even without an internet connection.
- **Token Usage Tracking:** CodinIT.dev tracks token usage for models accessed via Ollama, allowing you to monitor consumption.
- **Ollama's Own Documentation:** For more detailed information, consult the official [Ollama documentation](https://ollama.com/docs){ariaLabel="Ollama Documentation" rel="nofollow"}.


# OpenAI

> Learn how to configure and use official OpenAI models with CodinIT.dev.

CodinIT.dev supports accessing models directly through the official OpenAI API.

**Website:** <https://openai.com/>{ariaLabel="OpenAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Visit the [OpenAI Platform](https://platform.openai.com/){ariaLabel="OpenAI Platform" rel="nofollow"}. You'll need to create an account or sign in if you already have one.
2. **Navigate to API Keys:** Once logged in, go to the [API keys section](https://platform.openai.com/api-keys){ariaLabel="OpenAI API Keys Section" rel="nofollow"} of your account.
3. **Create a Key:** Click on "Create new secret key". It's good practice to give your key a descriptive name (e.g., "CodinIT.dev API Key").
4. **Copy the Key:** &#x2A;*Crucial:** Copy the generated API key immediately. For security reasons, OpenAI will not show it to you again. Store this key in a safe and secure location.

### Supported Models

CodinIT.dev is compatible with a variety of OpenAI models, including but not limited to:

- 'o3'
- `o3-mini` (medium reasoning effort)
- 'o4-mini'
- `o3-mini-high` (high reasoning effort)
- `o3-mini-low` (low reasoning effort)
- `o1`
- `o1-preview`
- `o1-mini`
- `gpt-4.5-preview`
- `gpt-4o`
- `gpt-4o-mini`
- 'gpt-4.1'
- 'gpt-4.1-mini'

For the most current list of available models and their capabilities, please refer to the official [OpenAI Models documentation](https://platform.openai.com/docs/models){ariaLabel="OpenAI Models Documentation" rel="nofollow"}.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings gear icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "OpenAI" from the "API Provider" dropdown menu.
3. **Enter API Key:** Paste your OpenAI API key into the "OpenAI API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown list.
5. **(Optional) Base URL:** If you need to use a proxy or a custom base URL for the OpenAI API, you can enter it here. Most users will not need to change this from the default.

### Tips and Notes

- **Pricing:** Be sure to review the [OpenAI Pricing page](https://openai.com/pricing){ariaLabel="OpenAI Pricing Page" rel="nofollow"} for detailed information on the costs associated with different models.
- **Azure OpenAI Service:** If you are looking to use the Azure OpenAI service, please note that specific documentation for Azure OpenAI with CodinIT.dev may be found separately, or you might need to configure it as an OpenAI-compatible endpoint if such functionality is supported by CodinIT.dev for custom configurations.


# Vertex AI

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics such as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# Together AI

CodinIT supports accessing open-source AI models through the Together AI platform, providing access to Llama 3.1, Code Llama, Mixtral, and other community-built models with transparent pricing.

::callout{icon="i-lucide-info"}
**Together AI** provides fast, affordable access to the best open-source AI models with transparent pricing and no vendor lock-in.
::

## Getting an API Key

::steps
### Sign Up for Together AI

Visit the [Together AI Platform](https://api.together.xyz/){ariaLabel="Together AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Qwen 2.5"}
  A powerful model with a balance of intelligence and speed.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Together AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Together AI API key into the "Together AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::


# Fireworks AI

CodinIT supports accessing high-performance AI models through the Fireworks AI platform, providing ultra-fast inference for Llama 3.1, Mixtral, Code Llama, and other open-source models.

::callout{icon="i-lucide-zap"}
**Fireworks AI** specializes in ultra-fast inference with industry-leading response times and production-ready performance for open-source AI models.
::

## Getting an API Key

::steps
### Sign Up for Fireworks AI

Visit the [Fireworks AI Platform](https://fireworks.ai/){ariaLabel="Fireworks AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Starcoder"}
  A powerful model specialized in code-related tasks.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Fireworks AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Fireworks AI API key into the "Fireworks AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::


# Introduction

![CodinIT Platform](https://codinit.dev/opengraph.png){style="border-radius: 12px; max-width: 100%;"}

## Platform Capabilities

The platform provides all the tools you need to create amazing websites, front-end applications as well as full-stack web applications from one browser tab - no installation required. CodinIT includes AI coding tools, real-time collaboration, and project sharing to give you a head start on your app creation journey.

| Capability       | Description                                 | Maturity Level |
| ---------------- | ------------------------------------------- | -------------- |
| Frontend / UI    | Build user interfaces & frontend            | üü¢ Mature      |
| Persistence      | Store and retrieve data                     | üü¢ Mature      |
| Authentication   | Handle user login and accounts              | üü¢ Mature      |
| Backend endpoint | API key protected endpoint such as OpenAI   | üü¢ Mature      |
| Deployment       | Publish, custom domains & deploy            | üü¢ Mature      |
| Collaboration    | Collaborate with other users within project | üü¢ Mature      |
| Real-time sync   | Sync data across users in real-time         | üü¢ Mature      |

## Quick Start Journey

To create your app on CodinIT, choose the guide that matches your needs:

::steps{level="3"}
### Tutorial

Step-by-step tutorial for a simple introduction to key features and concepts.

### Integrations

Go beyond default features by integrating with third parties like Supabase, Stripe or others.

### Prompt Engineering

Learn effective prompting strategies and get the most out of CodinIT.

### Custom Domain

Add your own domain to any CodinIT site app.

### Deploy

Learn how to deploy, share, and get traffic to your web applications with CodinIT.
::

## What is CodinIT

::callout{color="primary"}
**Letting Ordinary Visionaries Achieve Breakthroughs with Language-based Engineering.**

CodinIT is an AI-powered platform that lets you create and deploy apps from a single browser tab. The platform eliminates the complexity of traditional app-creation environments by combining coding, deployment, and collaboration tools in a single interface.
::

Typically, you must install programs, languages, and packages to build apps. However, on CodinIT, you can rely on AI to configure your environment so you can start building without coding experience.

The platform supports full-featured development and coding environments for those familiar with coding as well as those who are not, so there's no limit on what's possible.

### Key Features

- **Complete app generation** and setup from natural language description
- **Code suggestions** and autocomplete with AI assistance
- **Automated error detection** and debugging assistance
- **Documentation generation** for your applications
- **App deployment** to the cloud in a few clicks
- **Database integration** and hosting with Supabase native integration
- **Custom domain support** and connection

Your development environment structure will look like this:

```text
codinit-project/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îî‚îÄ‚îÄ config.json
```

## Essential Resources

::card-group
  :::card
  ---
  ariaLabel: Browse and use project templates
  icon: i-lucide-folder-open
  title: Templates
  ---
  Browse and use project templates to quickly start your next project.
  :::

  :::card
  ---
  ariaLabel: Get a full overview of how to build an app with CodinIT
  icon: i-lucide-play-circle
  title: Tutorial
  ---
  Get a full overview of how to build an app with CodinIT.
  :::

  :::card
  ---
  ariaLabel: Resolve issues in your development lifecycle
  icon: i-lucide-wrench
  title: Troubleshooting
  ---
  Resolve issues in your development lifecycle.
  :::

  :::card
  ---
  ariaLabel: Getting the Most Out of CodinIT
  icon: i-lucide-star
  title: Best Practices
  ---
  Getting the Most Out of CodinIT.
  :::

  :::card
  ---
  ariaLabel: Collaborate on your app in real time with teammates
  icon: i-lucide-users
  title: Teams
  ---
  Collaborate on your app in real time with teammates.
  :::
::

## Stay Connected

### Community & Support

::card-group
  :::card
  ---
  ariaLabel: Share ideas and let the community vote
  icon: i-lucide-lightbulb
  title: Feature Requests
  ---
  Have an idea? Share it and let the community vote
  :::

  :::card
  ---
  ariaLabel: Get help from our Community and Community Champions
  icon: i-lucide-help-circle
  title: Community Support
  ---
  Get help from our Community and Community Champions
  :::

  :::card{ariaLabel="Report a bug or an issue" icon="i-lucide-bug" title="Issues"}
  Found a bug or an issue? Let us know
  :::

  :::card
  ---
  ariaLabel: Direct support channel for paying users
  icon: i-lucide-headphones
  title: Priority Support
  ---
  Direct support channel for paying users
  :::
::

### Programs & Partnerships

::card-group
  :::card
  ---
  ariaLabel: Publish your app to get in front of thousands of people
  icon: i-lucide-rocket
  title: Launched
  ---
  Publish your app to get in front of thousands of people
  :::

  :::card
  ---
  ariaLabel: Join as an expert, or get help from our network of experts
  icon: i-lucide-handshake
  title: Partner Program
  ---
  Join as an expert, or get help from our network of experts
  :::

  :::card
  ---
  ariaLabel: Receive a 20% commission on the first 12 payments
  icon: i-lucide-percent
  title: Affiliate Program
  ---
  Receive a 20% commission on the first 12 payments
  :::
::

### Learn More about CodinIT

::card-group
  :::card
  ---
  ariaLabel: Learn more about CodinIT on our website
  icon: i-lucide-globe
  title: Visit our Website
  to: https://codinit.dev
  ---
  Explore our official website to learn more about CodinIT.
  :::

  :::card
  ---
  ariaLabel: Understand key development terms in our documentation
  icon: i-lucide-book-open
  title: Learn More
  to: https://docs.codinit.dev/getting-started/quickstart
  ---
  Familiarize yourself with key development terms by exploring our Documentation.
  :::

  :::card
  ---
  ariaLabel: prompting with codinit
  icon: i-lucide-briefcase
  title: Find out how to prompt with codinit
  to: https://codinit.dev/blog/prompting-with-codinit
  ---
  Learn how to prompt codinit for best results.
  :::

  :::card
  ---
  ariaLabel: Stay updated with the latest from the CodinIT team
  icon: i-lucide-megaphone
  title: Read Our Blog Announcements
  to: https://codinit.dev/blog
  ---
  Catch up on the latest news and updates from the CodinIT team.
  :::
::

::tip
üéâ Ready to start building? Choose your path from the Quick Start section above and begin creating your next application with CodinIT!
::


# Quickstart

Get your first CodinIT application running in under 10 minutes with this comprehensive quickstart guide.

::alert{color="green" icon="i-lucide-rocket"}
**New to CodinIT?** This guide walks you through the complete workflow from project creation to deployment.
::

## Create Your First Project

::steps{level="4"}
#### Step 1: Start a New Project

Navigate to your CodinIT dashboard and click **"Create New Project"**. Choose from:

- üì± **Mobile App** ‚Äì Responsive mobile-first applications
- üåê **Web Application** ‚Äì Full-stack web apps with backend
- üé® **Landing Page** ‚Äì Marketing sites and portfolios
- üìä **Dashboard** ‚Äì Data visualization and admin panels

#### Step 2: Describe Your App

Use natural language to describe what you want to build:

```text
Create a task management app with user authentication, 
the ability to add, edit, and delete tasks, and a 
dashboard showing task statistics.
```

#### Step 3: Review Generated Code

CodinIT will generate your complete application. Review the:

- Frontend components and styling
- Backend API endpoints
- Database schema and models
- Authentication setup

#### Step 4: Customize and Iterate

Make changes using natural language prompts or direct code editing:

```text
Add a priority system to tasks with high, medium, low options.
Style the app with a dark theme and modern card layout.
```
::

## Essential Editing Features

::card-group
  :::card{icon="i-lucide-edit" title="AI-Powered Editing"}
  Make changes using natural language prompts with instant preview
  :::

  :::card{icon="i-lucide-eye" title="Visual Editor"}
  Click and edit components directly with AI-driven visual controls
  :::

  :::card{icon="i-lucide-undo" title="Version Control"}
  Restore past versions instantly and bookmark important milestones
  :::

  :::card{icon="i-lucide-sparkles" title="Smart Suggestions"}
  Get AI suggestions for improvements and feature additions
  :::

  :::card{icon="i-lucide-image-plus" title="Media Integration"}
  Attach images and files directly to prompts for better context
  :::

  :::card{icon="i-lucide-layers" title="Component Library"}
  Access pre-built components and templates for faster development
  :::
::

## Knowledge Base Setup

Organize your project information for better AI assistance:

::steps{level="4"}
#### Step 1: Access Knowledge Base

Go to the Knowledge Base section in your dashboard.

#### Step 2: Add Project Documentation

Click "Add Entry" and categorize information under:

- üìå **Project Overview** ‚Äì Define objectives and scope
- üöÄ **Key Features** ‚Äì List core functionalities
- üé® **Design Guidelines** ‚Äì Document UI/UX principles
- üîß **Technical Requirements** ‚Äì Specify technologies and constraints

#### Step 3: Keep Information Current

Regularly review and update entries as your project evolves to ensure development stays aligned with your vision.
::

## Add Backend Capabilities

### Connect with Supabase

Supabase integration provides powerful backend capabilities with minimal setup:

::steps{level="4"}
#### Step 1: Create Supabase Project

Create an account on [Supabase](https://supabase.com){ariaLabel="Supabase Website" rel="nofollow"} and set up a new project.

#### Step 2: Link to CodinIT

In CodinIT, navigate to Settings ‚Üí Connect Supabase and follow the integration steps.

#### Step 3: Configure Data Models

Set up database tables, manage user data, and configure real-time subscriptions.

#### Step 4: Enable Authentication

Configure user authentication flows including email verification and social logins.
::

### Authentication Implementation

::tabs
  :::div{label="Setup Process"}
  **Step 1: Supabase Account Creation**
  
  Visit Supabase and sign up to access the project dashboard.
  
  **Step 2: Integration Configuration**
  
  Input your Supabase project URL and API keys to establish connection.
  
  **Step 3: Authentication Forms**
  
  Use CodinIT's AI form builder to create intuitive login and registration forms.
  
  **Step 4: Workflow Implementation**
  
  Set up Supabase Edge Functions for token validation and session management.
  :::

  :::div{label="Advanced Features"}
  **Email Verification**
  
  Configure automated email verification upon user registration.
  
  **Social Authentication**
  
  Enable Google, GitHub, and other OAuth provider integrations.
  
  **Role-Based Access**
  
  Implement user roles and permissions for secure access control.
  
  **Session Management**
  
  Handle user sessions with automatic refresh and secure logout.
  :::
::

## Testing and Deployment

### Preview Your Application

::alert{color="blue" icon="i-lucide-monitor"}
**Live Preview** - Every change is instantly reflected in the preview pane, allowing you to test functionality in real-time.
::

- **Responsive Testing** ‚Äì Check how your app looks on different device sizes
- **Feature Testing** ‚Äì Test user flows and interactions
- **Performance Monitoring** ‚Äì Monitor loading times and responsiveness

### Deploy to Production

::steps{level="3"}
### Step 1: Pre-Deployment Check

Review your application for:

- Functionality completeness
- Responsive design across devices
- Performance optimization
- Error handling

### Step 2: Choose Deployment Option

Select from multiple deployment options:

- **CodinIT Hosting** ‚Äì Instant deployment with custom domain support
- **GitHub Integration** ‚Äì Deploy via GitHub Pages or other CI/CD platforms
- **Custom Hosting** ‚Äì Export code for deployment anywhere

### Step 3: Configure Custom Domain

Add your custom domain for professional deployment:

- Point your domain to CodinIT's servers
- Configure SSL certificates automatically
- Set up redirect rules and routing
::

## Next Steps

::card-group
  :::card
  ---
  ariaLabel: Learn about team collaboration features
  icon: i-lucide-users
  title: Team Collaboration
  to: https://docs.codinit.dev/getting-started/teams
  ---
  Invite team members and collaborate in real-time
  :::

  :::card
  ---
  ariaLabel: Connect with third-party services and APIs
  icon: i-lucide-puzzle
  title: Integrations
  to: https://docs.codinit.dev/integrations/github
  ---
  Connect with third-party services and APIs
  :::

  :::card
  ---
  ariaLabel: Explore framework-specific development resources
  icon: i-lucide-code
  title: Developer Tools
  to: https://docs.codinit.dev/getting-started/developer-docs
  ---
  Explore framework-specific development resources
  :::
::

::tip
üéâ **Congratulations!** You've completed the quickstart guide. Your application is ready for further development and customization. Explore the advanced features to build even more powerful applications.
::


# Teams

CodinIT lets you build apps together, live. Invite your designer, developer, agency, or anyone else to your workspace. Everyone sees changes as they happen in real-time.

::callout{color="blue" icon="i-lucide-users"}
**Collaborative Development** - Experience seamless team collaboration with real-time editing, shared workspaces, and professional project management tools.
::

## Workspace Plans

Each subscription connects to a workspace with different collaboration capabilities:

::card-group
  :::card{color="primary" icon="i-lucide-user" title="Pro Subscription"}
  Personal workspaces with up to 2 collaborators per project. Collaborators use project owner credits for seamless cost management.
  :::

  :::card{color="green" icon="i-lucide-users" title="Teams Subscription"}
  Up to 20 users in workspace. Owners & admins manage users and projects. Shared credit pool for all team members.
  :::
::

## Workspace Management

### Create a Workspace

A workspace is your shared environment for building and collaborating on projects with your team.

::steps{level="3"}
### Step 1: Create New Workspace

Click **"Create new workspace"** from the dashboard or any existing project.

### Step 2: Name Your Workspace

Choose a descriptive name for your workspace that reflects your team or organization.

### Step 3: Choose a Plan

Select a subscription plan that fits your team size and collaboration requirements.
::

### Rename a Workspace

::steps{level="3"}
### Step 1: Switch to Workspace

Ensure you're in the correct workspace (switch if needed from the sidebar).

### Step 2: Access Settings

Navigate to **Settings** from your workspace dashboard.

### Step 3: Edit Details

Update the **Workspace name** and **description** to reflect changes in your team or project focus.
::

## Team Member Management

### Invite & Manage Collaborators

::steps{level="3"}
### Step 1: Upgrade Your Plan

Upgrade to the **Teams** tier if you're currently on a personal plan.

### Step 2: Send Invitations

Click **"Invite"** in a project or from the main dashboard to access the invitation system.

### Step 3: Add Team Members

Enter email addresses to send invitations to your team members and collaborators.

### Step 4: Team Integration

When invitations are accepted, members join your workspace and gain access to all shared projects.
::

### Role-Based Permissions

Different roles provide varying levels of access and control within your workspace:

| Action                                          | Owner | Admin | Editor |
| ----------------------------------------------- | ----- | ----- | ------ |
| Edit projects                                   | ‚úì     | ‚úì     | ‚úì      |
| Publish projects                                | ‚úì     | ‚úì     | ‚úì      |
| Connect/disconnect Supabase org to workspace    | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect Supabase project to projects | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub org to workspace      | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub repo to projects      | ‚úì     | ‚úì     | ‚úó      |
| Invite project-level collaborators              | ‚úì     | ‚úì     | ‚úó      |
| Transfer projects to other workspaces           | ‚úì     | ‚úì     | ‚úó      |
| Set roles for other users                       | ‚úì     | ‚úì     | ‚úó      |

### Role Descriptions

::field-group
  :::field{name="Owner" type="role"}
  Complete administrative control over the workspace, billing management, and all projects
  :::

  :::field{name="Admin" type="role"}
  Can manage most workspace and project aspects, but cannot modify other admin roles
  :::

  :::field{name="Editor" type="role"}
  Can edit and publish projects but cannot manage workspace settings, integrations, or user permissions
  :::
::

## Real-Time Collaboration Features

Once team members join your workspace, experience seamless real-time collaboration:

::card-group
  :::card
  ---
  ariaLabel: See team member cursors and live changes in real-time
  icon: i-lucide-mouse-pointer
  title: Live Cursors
  ---
  See team member cursors and live changes as they work in real-time
  :::

  :::card
  ---
  ariaLabel: Icons show who's currently online and active
  icon: i-lucide-circle-dot
  title: Team Presence
  ---
  Icons in top-right corner show who's currently online and active
  :::

  :::card
  ---
  ariaLabel: Edit any element together with immediate synchronization
  icon: i-lucide-edit
  title: Instant Editing
  ---
  Edit any element together with immediate synchronization across all users
  :::

  :::card
  ---
  ariaLabel: All modifications reflected immediately across all team members' screens
  icon: i-lucide-refresh-cw
  title: Change Synchronization
  ---
  All modifications reflected immediately across all team members' screens
  :::
::


# Developer Docs

Framework-focused prompting strategies and development patterns for building applications with CodinIT. Each section provides proven patterns, best practices, and ready-to-use prompts tailored to specific technology stacks.

::callout{color="blue" icon="i-heroicons-code-bracket"}
**Framework-Focused Prompts** - Specialized prompt patterns for Next.js, Python, Gradio, and Streamlit development. Copy, modify, and use these templates to build better applications faster.
::

## Overview

This library provides targeted prompting strategies for specific development frameworks. Each section contains proven patterns, best practices, and ready-to-use prompts tailored to the unique characteristics of each technology stack.

::alert{color="green" icon="i-heroicons-light-bulb"}
**Pro Tip** - These prompts are designed to work with any AI coding assistant. Adapt the examples to your specific project needs and requirements.
::

## Supported Frameworks

::card-group{cols="2"}
  :::card
  ---
  ariaLabel: Learn about Next.js Development
  icon: i-simple-icons-nextdotjs
  title: Next.js Development
  ---
  Full-stack React framework with SSR, API routes, and modern tooling for web applications.
  
  :badge[React]{color="blue" variant="outline"} :badge[TypeScript]{color="blue" variant="outline"} :badge[Full-Stack]{color="green" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Python Development
  icon: i-simple-icons-python
  title: Python Development
  ---
  Backend services, data processing, and general-purpose application development.
  
  :badge[Backend]{color="orange" variant="outline"} :badge[Data Science]{color="purple" variant="outline"} :badge[APIs]{color="emerald" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Gradio Development
  icon: i-heroicons-chart-bar
  title: Gradio Development
  ---
  Rapid ML model deployment and interactive data science applications.
  
  :badge[ML/AI]{color="red" variant="outline"} :badge[Interactive]{color="cyan" variant="outline"} :badge[Prototyping]{color="amber" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Streamlit Development
  icon: i-heroicons-presentation-chart-line
  title: Streamlit Development
  ---
  Data apps and dashboards with Python-first development approach.
  
  :badge[Data Apps]{color="indigo" variant="outline"} :badge[Dashboards]{color="pink" variant="outline"} :badge[Analytics]{color="teal" variant="outline"}
  :::
::

---

## Next.js Development

::callout{color="black" icon="i-simple-icons-nextdotjs"}
**Modern React framework with server-side rendering, API routes, and performance optimization.**
::

### Project Setup & Architecture

::tabs
  :::div{label="New Project Setup"}
  ```markdown
  Create a new Next.js 14 application with the following specifications:
  
  **Tech Stack:**
  - Next.js 14 with App Router
  - TypeScript for type safety
  - Tailwind CSS for styling
  - Prisma with PostgreSQL for database
  - NextAuth.js for authentication
  
  **Project Structure:**
  - `/app` directory structure with proper layouts
  - `/components` for reusable UI components
  - `/lib` for utilities and database configuration
  - `/types` for TypeScript definitions
  
  **Initial Features:**
  - Landing page with hero section and navigation
  - User authentication (sign up, login, logout)
  - Protected dashboard route
  - Responsive design with dark mode support
  
  Set up the basic project structure and create placeholder components.
  ```
  :::

  :::div{label="Component Architecture"}
  ```markdown
  Design a component architecture for a [describe app type] application:
  
  **Component Categories:**
  - UI components (buttons, inputs, cards)
  - Layout components (header, sidebar, footer)
  - Feature components (user profile, product listing)
  - Page components (home, dashboard, settings)
  
  **Requirements:**
  - TypeScript interfaces for all props
  - Compound component patterns where appropriate
  - Accessibility features (ARIA labels, keyboard navigation)
  - Consistent styling with Tailwind CSS variants
  
  Include examples of 2-3 components with proper TypeScript typing.
  ```
  :::
::

---

## Python Development

::callout{color="yellow" icon="i-simple-icons-python"}
**Versatile language for backend development, data processing, and API creation.**
::

### API Development

::tabs
  :::div{label="FastAPI Setup"}
  ```markdown
  Create a FastAPI application with the following requirements:
  
  **Features:**
  - RESTful API with CRUD operations
  - User authentication with JWT tokens
  - Database integration with SQLAlchemy
  - Input validation with Pydantic
  - Automated API documentation
  
  **Structure:**
  - `/models` for database models
  - `/routers` for API endpoints
  - `/schemas` for Pydantic models
  - `/auth` for authentication logic
  
  Include user registration, login, and protected endpoints.
  ```
  :::

  :::div{label="Data Processing"}
  ```markdown
  Build a data processing pipeline that:
  
  **Input Sources:**
  - CSV files from uploads
  - Database queries
  - API endpoints
  
  **Processing Steps:**
  - Data cleaning and validation
  - Statistical analysis
  - Visualization generation
  - Export to multiple formats
  
  **Output:**
  - Processed datasets
  - Summary statistics
  - Interactive charts
  - Automated reports
  
  Use pandas, numpy, and plotly for implementation.
  ```
  :::
::

---

## Gradio Development

::callout{color="red" icon="i-heroicons-chart-bar"}
**Rapid prototyping framework for ML models and interactive demos.**
::

### Interactive ML Applications

::tabs
  :::div{label="Model Demo Interface"}
  ```markdown
  Create a Gradio interface for [ML model type]:
  
  **Interface Components:**
  - File upload for input data
  - Parameter sliders for model tuning
  - Real-time prediction display
  - Confidence scores and explanations
  - Download results functionality
  
  **Features:**
  - Batch processing capabilities
  - Model comparison tools
  - Performance metrics display
  - Error handling and validation
  
  Include examples with sample data and clear instructions.
  ```
  :::

  :::div{label="Data Visualization Dashboard"}
  ```markdown
  Build a Gradio dashboard for data exploration:
  
  **Components:**
  - Dataset upload and preview
  - Interactive charts and plots
  - Statistical summary tables
  - Filter and search capabilities
  - Export functionality
  
  **Visualizations:**
  - Distribution plots
  - Correlation matrices
  - Time series analysis
  - Geographic mapping (if applicable)
  
  Make it responsive and user-friendly for non-technical users.
  ```
  :::
::

---

## Streamlit Development

::callout{color="red" icon="i-heroicons-presentation-chart-line"}
**Python-first framework for building data applications and interactive dashboards.**
::

### Data Dashboards

::tabs
  :::div{label="Analytics Dashboard"}
  ```markdown
  Create a comprehensive analytics dashboard using Streamlit:
  
  **Data Sources:**
  - Multiple data source connections (CSV, database, API)
  - Real-time data refresh capabilities
  - Data caching for performance
  - Error handling for data loading
  
  **Dashboard Layout:**
  - Multi-page application structure
  - Sidebar navigation and filters
  - Responsive grid layout
  - Customizable date ranges
  - Export functionality
  
  **Visualizations:**
  - KPI metrics with st.metric()
  - Interactive charts with Plotly
  - Data tables with filtering/sorting
  - Geographic visualizations
  
  Include caching and performance optimization.
  ```
  :::

  :::div{label="Machine Learning App"}
  ```markdown
  Build a complete ML application with Streamlit:
  
  **Features:**
  - Model training interface
  - Hyperparameter tuning
  - Performance evaluation
  - Prediction interface
  - Model deployment options
  
  **Components:**
  - Data upload and preprocessing
  - Model selection and training
  - Results visualization
  - Model comparison tools
  - Export trained models
  
  Include proper error handling and user guidance.
  ```
  :::
::

---

## Development Best Practices

::alert{color="amber" icon="i-heroicons-star"}
**Quality Assurance** - Follow these practices for professional-grade applications regardless of framework choice.
::

### Code Quality Guidelines

::steps{level="4"}
#### Step 1: Planning & Design

Start with clear requirements and architecture design before implementation.

#### Step 2: Iterative Development

Build features incrementally with regular testing and validation.

#### Step 3: Code Review

Implement peer review processes for maintaining code quality standards.

#### Step 4: Deployment & Monitoring

Set up automated deployment with proper monitoring and error tracking.
::

### Framework Selection Guide

Choose the right framework based on your project requirements:

| Framework     | Best For            | Use Cases                         |
| ------------- | ------------------- | --------------------------------- |
| **Next.js**   | Full-stack web apps | E-commerce, SaaS, Marketing sites |
| **Python**    | Backend services    | APIs, Data processing, Automation |
| **Gradio**    | ML demos            | Model prototyping, Research demos |
| **Streamlit** | Data applications   | Analytics dashboards, BI tools    |

## Getting Started

::alert{color="green" icon="i-heroicons-rocket-launch"}
**Ready to start building?** Choose your framework and begin with the appropriate prompt templates. Remember to adapt these examples to your specific project needs.
::

### Quick Start Checklist

::list{icon="i-heroicons-check"}
- Identify your project requirements and constraints
- Choose the appropriate framework for your use case
- Start with a basic project setup prompt
- Iterate with specific feature implementation prompts
- Apply best practices for code quality and security
- Set up proper testing and deployment workflows
::

::card
---
color: blue
icon: i-heroicons-chat-bubble-left-right
title: Need Help?
---
These prompts are starting points. Feel free to modify them based on your specific requirements, and don't hesitate to break complex tasks into smaller, more manageable prompts.

**Pro Tip:** Combine multiple prompts for complex applications, building one feature at a time.
::


# GitHub

Import your existing GitHub repositories into CodinIT to leverage AI-powered development on your current codebase.

::callout{icon="i-simple-icons-github"}
**Import Existing Code:** Connect your GitHub repositories to CodinIT for AI-enhanced development of existing projects.
::

## Why Import GitHub Repositories?

::card-group
  :::card{icon="i-lucide-code" title="Leverage Existing Code"}
  Build upon your existing codebase with AI assistance instead of starting from scratch.
  :::

  :::card{icon="i-lucide-zap" title="Modernize Legacy Apps"}
  Add new features to older projects using modern AI development techniques.
  :::

  :::card{icon="i-lucide-users" title="Team Transition"}
  Gradually migrate team workflows to AI-assisted development.
  :::

  :::card{icon="i-lucide-git-branch" title="Maintain History"}
  Preserve complete git history while adding AI development capabilities.
  :::
::

## Supported Repository Types

CodinIT can import and enhance various types of GitHub repositories:

::tabs
  :::div{label="Web Applications"}
  **Frontend and full-stack applications:**
  
  - **React/Next.js** - Add new components and features with AI assistance.
  - **Vue/Nuxt** - Enhance existing applications with AI-generated code.
  - **Angular** - Modernize components and add intelligent features.
  - **Vanilla JavaScript** - Upgrade to modern frameworks with AI guidance.
  :::

  :::div{label="Backend Services"}
  **APIs and server applications:**
  
  - **Node.js/Express** - Add new endpoints and business logic.
  - **Python/Django** - Enhance data processing and API capabilities.
  - **PHP/Laravel** - Modernize legacy PHP applications.
  - **Ruby/Rails** - Add new features to existing Rails apps.
  :::

  :::div{label="Data & Analytics"}
  **Data processing and analysis projects:**
  
  - **Python Data Science** - Enhance analysis with AI-generated insights.
  - **Jupyter Notebooks** - Add interactive features and visualizations.
  - **R Projects** - Integrate modern web interfaces.
  - **SQL Databases** - Generate query optimization and reporting features.
  :::
::

## Repository Import Process

::steps
### Connect GitHub Account

Authorize CodinIT to access your GitHub repositories in your settings.

### Choose Repository to Import

Select the public or private GitHub repository you want to enhance with AI development.

### Configure AI Model

Choose the AI provider that best fits your project needs.

### Import and Analyze

CodinIT will analyze your codebase and prepare it for AI-enhanced development.
::

## Post-Import Development

Once imported, use AI to understand your codebase, add new features, and modernize your application.

::collapsible{title="Feature Enhancement Examples"}
**Add Authentication to Existing App:**

```text
Add user authentication to this application:
- User registration and login pages
- Protected routes and middleware
- Session management
- Password reset functionality
- Integration with existing database schema
```

**Modernize UI Components:**

```text
Modernize the user interface:
- Convert existing components to modern design system
- Add responsive design for mobile compatibility
- Implement dark mode support
- Improve accessibility features
```

**Add API Endpoints:**

```text
Add new API functionality:
- RESTful endpoints for data management
- Input validation and error handling
- Database integration with existing schema
- API documentation and testing
```
::

## Best Practices for Repository Import

### Pre-Import Preparation

::checklist
- Clean up unused files and dependencies.
- Ensure repository has clear folder structure.
- Add basic README with project description.
- Remove sensitive data and API keys.
- Create main branch with stable code.
::

### Post-Import Optimization

::tabs
  :::div{label="Code Organization"}
  **Organize code for better AI understanding:**
  
  - Use descriptive file and folder names.
  - Add comments explaining complex business logic.
  - Separate concerns into logical modules.
  - Maintain consistent coding style throughout.
  :::

  :::div{label="AI Prompting"}
  **Write effective prompts for existing codebases:**
  
  - Reference specific files and functions in prompts.
  - Explain existing patterns to maintain consistency.
  - Ask for incremental improvements rather than rewrites.
  - Use AI to understand code before making changes.
  :::
::


# Plugins

Connect CodinIT with your favorite tools and services to build production-ready applications faster. From version control to databases, deployment platforms, and AI providers.

::callout{icon="i-heroicons-information-circle"}
**Integration Philosophy:** CodinIT.dev is designed to work with your existing development ecosystem, not replace it. These integrations ensure you maintain full control over your codebase while leveraging AI-powered development tools.
::

## Database Integrations

::tabs
  :::div{label="SQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-postgresql" title="PostgreSQL"}
      Industry-standard relational database with advanced features, JSON support, and excellent performance.
      :::::
    
      :::::card{icon="i-simple-icons-mysql" title="MySQL"}
      Popular open-source relational database known for reliability and ease of use.
      :::::
    
      :::::card{icon="i-simple-icons-sqlite" title="SQLite"}
      Lightweight, file-based SQL database perfect for development and small applications.
      :::::
    
      :::::card{icon="i-lucide-database" title="Microsoft SQL Server"}
      Enterprise-grade database with advanced analytics and business intelligence features.
      :::::
    ::::
  :::

  :::div{label="NoSQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-mongodb" title="MongoDB"}
      Document-oriented database with flexible schema and horizontal scaling capabilities.
      :::::
    
      :::::card{icon="i-simple-icons-redis" title="Redis"}
      In-memory data structure store used as database, cache, and message broker.
      :::::
    
      :::::card{icon="i-lucide-database" title="CouchDB"}
      Document database with multi-master replication and web-based administration.
      :::::
    
      :::::card{icon="i-lucide-layers" title="DynamoDB"}
      Amazon's managed NoSQL database service with automatic scaling and high availability.
      :::::
    ::::
  :::

  :::div{label="Cloud Database Services"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-supabase" title="Supabase"}
      Open-source Firebase alternative with PostgreSQL, real-time subscriptions, and built-in authentication.
      :::::
    
      :::::card{icon="i-simple-icons-firebase" title="Firebase"}
      Google's mobile and web application development platform with real-time database and hosting.
      :::::
    
      :::::card{icon="i-simple-icons-planetscale" title="PlanetScale"}
      Serverless MySQL platform with branching, schema migrations, and automatic scaling.
      :::::
    
      :::::card{icon="i-lucide-database" title="Neon"}
      Serverless PostgreSQL with automatic scaling, branching, and point-in-time recovery.
      :::::
    ::::
  :::
::

## AI Model Providers

::card-group{cols="2"}
  :::card{icon="i-lucide-brain" title="Anthropic Claude"}
  Advanced reasoning capabilities with Claude 4 Sonnet and other models for sophisticated code generation and problem-solving.
  :::

  :::card{icon="i-lucide-bot" title="OpenAI GPT"}
  Industry-leading language models including GPT-4, GPT-4 Turbo, and o1 for intelligent app development.
  :::

  :::card{icon="i-lucide-sparkles" title="Google Gemini"}
  Google's multimodal AI with Gemini Pro and Flash models for fast and efficient development.
  :::

  :::card{icon="i-lucide-server" title="Local Models (Ollama)"}
  Run AI models locally for privacy, offline development, and cost control.
  :::
::

## Deployment Platforms

::card-group{cols="2"}
  :::card{icon="i-simple-icons-vercel" title="Vercel"}
  Optimized for modern frontend frameworks with automatic deployments and edge computing.
  :::

  :::card{icon="i-simple-icons-netlify" title="Netlify"}
  All-in-one platform for web projects with forms, functions, and identity management.
  :::

  :::card{icon="i-simple-icons-amazonaws" title="AWS"}
  Comprehensive cloud platform with extensive services for any application size.
  :::

  :::card{icon="i-simple-icons-googlecloud" title="Google Cloud"}
  Google's cloud platform with AI/ML services and global infrastructure.
  :::
::

## Authentication & Security

::card-group{cols="2"}
  :::card{icon="i-simple-icons-auth0" title="Auth0"}
  Enterprise identity platform with social logins, multi-factor authentication, and compliance features.
  :::

  :::card{icon="i-simple-icons-firebase" title="Firebase Auth"}
  Google's authentication service with social providers and email/password authentication.
  :::

  :::card{icon="i-simple-icons-supabase" title="Supabase Auth"}
  Open-source authentication with built-in database integration and social providers.
  :::

  :::card{icon="i-lucide-key" title="NextAuth.js"}
  Open-source authentication library for Next.js applications with multiple provider support.
  :::
::

## Payment Processing

::card-group{cols="2"}
  :::card{icon="i-simple-icons-stripe" title="Stripe"}
  Industry-leading payment platform with comprehensive APIs and global coverage.
  :::

  :::card{icon="i-simple-icons-paypal" title="PayPal"}
  Global payment platform with buyer protection and multiple payment methods.
  :::
::

## Communication & Notifications

::card-group{cols="2"}
  :::card{icon="i-lucide-mail" title="Resend"}
  Developer-first email API with excellent deliverability and React email templates.
  :::

  :::card{icon="i-simple-icons-mailgun" title="Mailgun"}
  Powerful email API for developers with advanced routing and analytics.
  :::
::

## Analytics & Monitoring

::card-group{cols="2"}
  :::card{icon="i-simple-icons-googleanalytics" title="Google Analytics"}
  Comprehensive web analytics platform with audience insights and conversion tracking.
  :::

  :::card{icon="i-lucide-activity" title="Umami"}
  Privacy-focused, open-source web analytics alternative to Google Analytics.
  :::
::


# Anthropic

> Learn how to configure and use Anthropic Claude models with CodinIT.dev. Covers API key setup, model selection, and advanced features like prompt caching.

**Website:** <https://www.anthropic.com/>{ariaLabel="Anthropic Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [Anthropic Console](https://console.anthropic.com/){ariaLabel="Anthropic Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the [API keys](https://console.anthropic.com/settings/keys){ariaLabel="Anthropic API Keys Settings" rel="nofollow"} section.
3. **Create a Key:** Click "Create Key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following Anthropic Claude models:

- `claude-opus-4-20250514`
- `claude-opus-4-20250514:thinking` (Extended Thinking variant)
- `claude-sonnet-4-20250514` (Recommended)
- `claude-sonnet-4-20250514:thinking` (Extended Thinking variant)
- `claude-3-7-sonnet-20250219`
- `claude-3-7-sonnet-20250219:thinking` (Extended Thinking variant)
- `claude-3-5-sonnet-20241022`
- `claude-3-5-haiku-20241022`
- `claude-3-opus-20240229`
- `claude-3-haiku-20240307`

See [Anthropic's Model Documentation](https://docs.anthropic.com/en/docs/about-claude/models){ariaLabel="Anthropic Model Documentation" rel="nofollow"} for more details on each model's capabilities.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "Anthropic" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your Anthropic API key into the "Anthropic API Key" field.
4. **Select Model:** Choose your desired Claude model from the "Model" dropdown.
5. **(Optional) Custom Base URL:** If you need to use a custom base URL for the Anthropic API, check "Use custom base URL" and enter the URL. Most users won't need to adjust this setting.

### Extended Thinking

Anthropic models offer an "Extended Thinking" feature, designed to give them enhanced reasoning capabilities for complex tasks. This feature allows the model to output its step-by-step thought process before delivering a final answer, providing transparency and enabling more thorough analysis for challenging prompts.

When extended thinking is in CodinIT.dev, the model generates `thinking` content blocks that detail its internal reasoning. These insights are then incorporated into its final response.
CodinIT.dev users can leverage this by checking the `Enable Extended Thinking` box below the model selection menu after selecting a Claude Model from any provider.

**Key Aspects of Extended Thinking:**

- **Supported Models:** This feature is available for select models, including variants of Claude Opus 4, Claude Sonnet 4, and Claude Sonnet 3.7. The specific models listed in the "Supported Models" section above with the `:thinking` suffix are pre-configured in CodinIT.dev to utilize this.
- **Summarized Thinking (Claude 4):** For Claude 4 models, the API returns a summary of the full thinking process to balance insight with efficiency and prevent misuse. You are billed for the full thinking tokens, not just the summary.
- **Streaming:** Extended thinking responses, including the `thinking` blocks, can be streamed.
- **Tool Use & Prompt Caching:** Extended thinking interacts with tool use (requiring thinking blocks to be passed back) and prompt caching (with specific behaviors around cache invalidation and context).

For comprehensive details on how extended thinking works, including API examples, interaction with tool use, prompt caching, and pricing, please refer to the [official Anthropic documentation on Extended Thinking](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking){ariaLabel="Anthropic Extended Thinking Documentation" rel="nofollow"}.

### Tips and Notes

- **Prompt Caching:** Claude 3 models support [prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching){ariaLabel="Anthropic Prompt Caching Documentation" rel="nofollow"}, which can significantly reduce costs and latency for repeated prompts.
- **Context Window:** Claude models have large context windows (200,000 tokens), allowing you to include a significant amount of code and context in your prompts.
- **Pricing:** Refer to the [Anthropic Pricing](https://www.anthropic.com/pricing){ariaLabel="Anthropic Pricing Page" rel="nofollow"} page for the latest pricing information.
- **Rate Limits:** Anthropic has strict rate limits based on [usage tiers](https://docs.anthropic.com/en/api/rate-limits#requirements-to-advance-tier){ariaLabel="Anthropic API Rate Limits Documentation" rel="nofollow"}.


# DeepSeek

> Learn how to configure and use DeepSeek models like deepseek-chat and deepseek-reasoner with CodinIT.dev.

CodinIT.dev supports accessing models through the DeepSeek API, including `deepseek-chat` and `deepseek-reasoner`.

**Website:** <https://platform.deepseek.com/>{ariaLabel="DeepSeek Platform Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [DeepSeek Platform](https://platform.deepseek.com/){ariaLabel="DeepSeek Platform" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Find your API keys in the [API keys](https://platform.deepseek.com/api_keys){ariaLabel="DeepSeek API Keys Section" rel="nofollow"} section of the platform.
3. **Create a Key:** Click "Create new API key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following DeepSeek models:

- `deepseek-v3-0324` (Recommended for coding tasks)
- `deepseek-r1` (Recommended for reasoning tasks)

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the ‚öôÔ∏è icon in the CodinIT.dev panel.
2. **Select Provider:** Choose "DeepSeek" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your DeepSeek API key into the "DeepSeek API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown.

### Tips and Notes

- **Pricing:** Refer to the [DeepSeek Pricing](https://api-docs.deepseek.com/quick_start/pricing/){ariaLabel="DeepSeek Pricing Page" rel="nofollow"} page for details on model costs.


# Google Gemini

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){ariaLabel="Learn more about GCP Vertex AI" rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){ariaLabel="Google Cloud Console" rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){ariaLabel="GCP Vertex AI Access Control documentation" rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){ariaLabel="Download Visual Studio Code" rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){ariaLabel="Google Cloud CLI installation guide" rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){ariaLabel="GCP IAM Best Practices" rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics suchs as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){ariaLabel="Learn more about GCP Vertex AI Quotas" rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){ariaLabel="GCP Vertex AI Documentation" rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# xAI Groq

> Learn how to configure and use xAI's Grok models with CodinIT.dev, including API key setup, supported models, and reasoning capabilities.

xAI is the company behind Grok, a large language model known for its conversational abilities and large context window. Grok models are designed to provide helpful, informative, and contextually relevant responses.

**Website:** <https://x.ai/>{ariaLabel="xAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [xAI Console](https://console.x.ai/){ariaLabel="xAI Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the API keys section in your dashboard.
3. **Create a Key:** Click to create a new API key. Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following xAI Grok models:

#### Grok-3 Models

- `grok-3-beta` (Default) - xAI's Grok-3 beta model with 131K context window
- `grok-3-fast-beta` - xAI's Grok-3 fast beta model with 131K context window
- `grok-3-mini-beta` - xAI's Grok-3 mini beta model with 131K context window
- `grok-3-mini-fast-beta` - xAI's Grok-3 mini fast beta model with 131K context window

#### Grok-2 Models

- `grok-2-latest` - xAI's Grok-2 model - latest version with 131K context window
- `grok-2` - xAI's Grok-2 model with 131K context window
- `grok-2-1212` - xAI's Grok-2 model (version 1212) with 131K context window

#### Grok Vision Models

- `grok-2-vision-latest` - xAI's Grok-2 Vision model - latest version with image support and 32K context window
- `grok-2-vision` - xAI's Grok-2 Vision model with image support and 32K context window
- `grok-2-vision-1212` - xAI's Grok-2 Vision model (version 1212) with image support and 32K context window
- `grok-vision-beta` - xAI's Grok Vision Beta model with image support and 8K context window

#### Legacy Models

- `grok-beta` - xAI's Grok Beta model (legacy) with 131K context window

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "xAI" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your xAI API key into the "xAI API Key" field.
4. **Select Model:** Choose your desired Grok model from the "Model" dropdown.

### Reasoning Capabilities

Grok 3 Mini models feature specialized reasoning capabilities, allowing them to "think before responding" - particularly useful for complex problem-solving tasks.

#### Reasoning-Enabled Models

Reasoning is only supported by:

- `grok-3-mini-beta`
- `grok-3-mini-fast-beta`

The Grok 3 models `grok-3-beta` and `grok-3-fast-beta` do not support reasoning.

#### Controlling Reasoning Effort

When using reasoning-enabled models, you can control how hard the model thinks with the `reasoning_effort` parameter:

- `low`: Minimal thinking time, using fewer tokens for quick responses
- `high`: Maximum thinking time, leveraging more tokens for complex problems

Choose `low` for simple queries that should complete quickly, and `high` for harder problems where response latency is less important.

#### Key Features

- **Step-by-Step Problem Solving**: The model thinks through problems methodically before delivering an answer
- **Math & Quantitative Strength**: Excels at numerical challenges and logic puzzles
- **Reasoning Trace Access**: The model's thinking process is available via the `reasoning_content` field in the response completion object

### Tips and Notes

- **Context Window:** Most Grok models feature large context windows (up to 131K tokens), allowing you to include substantial amounts of code and context in your prompts.
- **Vision Capabilities:** Select vision-enabled models (`grok-2-vision-latest`, `grok-2-vision`, etc.) when you need to process or analyze images.
- **Pricing:** Pricing varies by model, with input costs ranging from $0.3 to $5.0 per million tokens and output costs from $0.5 to $25.0 per million tokens. Refer to the xAI documentation for the most current pricing information.
- **Performance Tradeoffs:** "Fast" variants typically offer quicker response times but may have higher costs, while "mini" variants are more economical but may have reduced capabilities.


# Mistral

Connect Mistral AI's sophisticated models to CodinIT.dev for precise, efficient app development.

::callout{icon="i-lucide-sparkles"}
**Mistral AI Precision** - Experience French AI excellence with Mistral's models known for precise instruction following, exceptional coding capabilities, and efficient performance.
::

## Why Choose Mistral for Development?

::card-group
  :::card{icon="i-lucide-code" title="Coding Specialist"}
  Codestral model specifically designed for software development tasks.
  :::

  :::card{icon="i-lucide-target" title="Precise Instructions"}
  Exceptional accuracy in following detailed technical specifications.
  :::

  :::card{icon="i-lucide-zap" title="Efficient Performance"}
  High-quality outputs with optimized token usage and speed.
  :::

  :::card{icon="i-lucide-globe" title="Multilingual Excellence"}
  Superior support for multiple programming languages and human languages.
  :::
::

## Available Mistral Models

| Model             | Type    | Strengths           | Best For             | Context |
| ----------------- | ------- | ------------------- | -------------------- | ------- |
| **Mistral Large** | General | Advanced reasoning  | Complex applications | 128k    |
| **Codestral**     | Coding  | Code specialization | Software development | 32k     |
| **Mixtral 8x7b**  | General | High throughput     | High-volume usage    | 32k     |
| **Mistral 7b**    | General | Fast responses      | Quick iterations     | 32k     |

## API Key Setup

::steps
### Create Mistral Account

Visit [Mistral Console](https://console.mistral.ai/){ariaLabel="Mistral Console" rel="nofollow"} and create your developer account.

### Generate API Key

Navigate to the API Keys section and create a new key.

### Secure Key Storage

Store your API key securely in your project's environment variables.
::

## CodinIT Configuration

To configure the Mistral provider in CodinIT, navigate to your project settings, select "Mistral" from the AI Provider dropdown, and enter your API key.

## Development Examples

### Full-Stack Application Development

```typescript
// Example: E-commerce platform with Codestral
const prompt = `
Create a complete e-commerce platform using Next.js and TypeScript:
- Product catalog with search and filtering
- Shopping cart with persistent state
- User authentication and profiles
`;
```

### API Development

```python
# Example: Microservices with FastAPI
prompt = """
Design a microservices architecture for a content management system:
- User service with OAuth integration
- Content service with version control
- Media service with CDN integration
"""
```

## Best Practices

### Prompt Engineering

::card-group
  :::card{icon="i-lucide-list" title="Detailed Specifications"}
  Provide comprehensive requirements and technical constraints.
  :::

  :::card{icon="i-lucide-layers" title="Structured Context"}
  Organize information clearly with priorities and dependencies.
  :::

  :::card{icon="i-lucide-code" title="Code Context"}
  Include relevant existing code patterns and architecture.
  :::

  :::card{icon="i-lucide-refresh-cw" title="Iterative Refinement"}
  Build complex features incrementally with feedback loops.
  :::
::

## Troubleshooting Guide

### Common Issues

::accordion
  :::card{title="API Key Type Mismatch"}
  **Resolution Steps:**
  
  1. Verify you're using the correct API key type for your model.
  2. Use Codestral API key specifically for Codestral model.
  3. Use General API key for other Mistral models.
  :::

  :::card{title="Model Access Denied"}
  **Resolution Steps:**
  
  1. Verify your account has access to the selected model.
  2. Check billing status and account standing.
  3. Ensure API key hasn't expired or been revoked.
  :::
::


# Ollama

CodinIT.dev supports running models locally using Ollama. This approach offers privacy, offline access, and potentially reduced costs. It requires some initial setup and a sufficiently powerful computer. Because of the present state of consumer hardware, it's not recommended to use Ollama with CodinIT.dev as performance will likely be poor for average hardware configurations.

**Website:** <https://ollama.com/>{ariaLabel="Ollama Website" rel="nofollow"}

### Setting up Ollama

1. **Download and Install Ollama:**
   Obtain the Ollama installer for your operating system from the [Ollama website](https://ollama.com/){ariaLabel="Ollama Website" rel="nofollow"} and follow their installation guide. Ensure Ollama is running. You can typically start it with:
   ```bash
   ollama serve
   ```
2. **Download a Model:**
   Ollama supports a wide variety of models. A list of available models can be found on the [Ollama model library](https://ollama.com/library){ariaLabel="Ollama Model Library" rel="nofollow"}. Some models recommended for coding tasks include:
   - `codellama:7b-code` (a good, smaller starting point)
   - `codellama:13b-code` (offers better quality, larger size)
   - `codellama:34b-code` (provides even higher quality, very large)
   - `qwen2.5-coder:32b`
   - `mistralai/Mistral-7B-Instruct-v0.1` (a solid general-purpose model)
   - `deepseek-coder:6.7b-base` (effective for coding)
   - `llama3:8b-instruct-q5_1` (suitable for general tasks)
   :brTo download a model, open your terminal and execute:
   ```bash
   ollama pull <model_name>
   ```
   :brFor instance:
   ```bash
   ollama pull qwen2.5-coder:32b
   ```
3. **Configure the Model's Context Window:**
   By default, Ollama models often use a context window of 2048 tokens, which can be insufficient for many CodinIT.dev requests. A minimum of 12,000 tokens is advisable for decent results, with 32,000 tokens being ideal. To adjust this, you'll modify the model's parameters and save it as a new version. :br First, load the model (using `qwen2.5-coder:32b` as an example):
   ```bash
   ollama run qwen2.5-coder:32b
   ```
   :brOnce the model is loaded within the Ollama interactive session, set the context size parameter:
   ```text
   /set parameter num_ctx 32768
   ```
   :brThen, save this configured model with a new name:
   ```text
   /save your_custom_model_name
   ```
   :br(Replace `your_custom_model_name` with a name of your choice.)
4. **Configure CodinIT.dev:**
   - Open the CodinIT.dev sidebar (usually indicated by the CodinIT.dev icon).
   - Click the settings gear icon (‚öôÔ∏è).
   - Select "ollama" as the API Provider.
   - Enter the Model name you saved in the previous step (e.g., `your_custom_model_name`).
   - (Optional) Adjust the base URL if Ollama is running on a different machine or port. The default is `http://localhost:11434`.
   - (Optional) Configure the Model context size in CodinIT.dev's Advanced settings. This helps CodinIT.dev manage its context window effectively with your customized Ollama model.

### Tips and Notes

- **Resource Demands:** Running large language models locally can be demanding on system resources. Ensure your computer meets the requirements for your chosen model.
- **Model Choice:** Experiment with various models to discover which best fits your specific tasks and preferences.
- **Offline Capability:** After downloading a model, you can use CodinIT.dev with that model even without an internet connection.
- **Token Usage Tracking:** CodinIT.dev tracks token usage for models accessed via Ollama, allowing you to monitor consumption.
- **Ollama's Own Documentation:** For more detailed information, consult the official [Ollama documentation](https://ollama.com/docs){ariaLabel="Ollama Documentation" rel="nofollow"}.


# OpenAI

> Learn how to configure and use official OpenAI models with CodinIT.dev.

CodinIT.dev supports accessing models directly through the official OpenAI API.

**Website:** <https://openai.com/>{ariaLabel="OpenAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Visit the [OpenAI Platform](https://platform.openai.com/){ariaLabel="OpenAI Platform" rel="nofollow"}. You'll need to create an account or sign in if you already have one.
2. **Navigate to API Keys:** Once logged in, go to the [API keys section](https://platform.openai.com/api-keys){ariaLabel="OpenAI API Keys Section" rel="nofollow"} of your account.
3. **Create a Key:** Click on "Create new secret key". It's good practice to give your key a descriptive name (e.g., "CodinIT.dev API Key").
4. **Copy the Key:** &#x2A;*Crucial:** Copy the generated API key immediately. For security reasons, OpenAI will not show it to you again. Store this key in a safe and secure location.

### Supported Models

CodinIT.dev is compatible with a variety of OpenAI models, including but not limited to:

- 'o3'
- `o3-mini` (medium reasoning effort)
- 'o4-mini'
- `o3-mini-high` (high reasoning effort)
- `o3-mini-low` (low reasoning effort)
- `o1`
- `o1-preview`
- `o1-mini`
- `gpt-4.5-preview`
- `gpt-4o`
- `gpt-4o-mini`
- 'gpt-4.1'
- 'gpt-4.1-mini'

For the most current list of available models and their capabilities, please refer to the official [OpenAI Models documentation](https://platform.openai.com/docs/models){ariaLabel="OpenAI Models Documentation" rel="nofollow"}.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings gear icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "OpenAI" from the "API Provider" dropdown menu.
3. **Enter API Key:** Paste your OpenAI API key into the "OpenAI API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown list.
5. **(Optional) Base URL:** If you need to use a proxy or a custom base URL for the OpenAI API, you can enter it here. Most users will not need to change this from the default.

### Tips and Notes

- **Pricing:** Be sure to review the [OpenAI Pricing page](https://openai.com/pricing){ariaLabel="OpenAI Pricing Page" rel="nofollow"} for detailed information on the costs associated with different models.
- **Azure OpenAI Service:** If you are looking to use the Azure OpenAI service, please note that specific documentation for Azure OpenAI with CodinIT.dev may be found separately, or you might need to configure it as an OpenAI-compatible endpoint if such functionality is supported by CodinIT.dev for custom configurations.


# Vertex AI

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics such as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# Together AI

CodinIT supports accessing open-source AI models through the Together AI platform, providing access to Llama 3.1, Code Llama, Mixtral, and other community-built models with transparent pricing.

::callout{icon="i-lucide-info"}
**Together AI** provides fast, affordable access to the best open-source AI models with transparent pricing and no vendor lock-in.
::

## Getting an API Key

::steps
### Sign Up for Together AI

Visit the [Together AI Platform](https://api.together.xyz/){ariaLabel="Together AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Qwen 2.5"}
  A powerful model with a balance of intelligence and speed.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Together AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Together AI API key into the "Together AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::


# Fireworks AI

CodinIT supports accessing high-performance AI models through the Fireworks AI platform, providing ultra-fast inference for Llama 3.1, Mixtral, Code Llama, and other open-source models.

::callout{icon="i-lucide-zap"}
**Fireworks AI** specializes in ultra-fast inference with industry-leading response times and production-ready performance for open-source AI models.
::

## Getting an API Key

::steps
### Sign Up for Fireworks AI

Visit the [Fireworks AI Platform](https://fireworks.ai/){ariaLabel="Fireworks AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Starcoder"}
  A powerful model specialized in code-related tasks.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Fireworks AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Fireworks AI API key into the "Fireworks AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::


# Introduction

![CodinIT Platform](https://codinit.dev/opengraph.png){style="border-radius: 12px; max-width: 100%;"}

## Platform Capabilities

The platform provides all the tools you need to create amazing websites, front-end applications as well as full-stack web applications from one browser tab - no installation required. CodinIT includes AI coding tools, real-time collaboration, and project sharing to give you a head start on your app creation journey.

| Capability       | Description                                 | Maturity Level |
| ---------------- | ------------------------------------------- | -------------- |
| Frontend / UI    | Build user interfaces & frontend            | üü¢ Mature      |
| Persistence      | Store and retrieve data                     | üü¢ Mature      |
| Authentication   | Handle user login and accounts              | üü¢ Mature      |
| Backend endpoint | API key protected endpoint such as OpenAI   | üü¢ Mature      |
| Deployment       | Publish, custom domains & deploy            | üü¢ Mature      |
| Collaboration    | Collaborate with other users within project | üü¢ Mature      |
| Real-time sync   | Sync data across users in real-time         | üü¢ Mature      |

## Quick Start Journey

To create your app on CodinIT, choose the guide that matches your needs:

::steps{level="3"}
### Tutorial

Step-by-step tutorial for a simple introduction to key features and concepts.

### Integrations

Go beyond default features by integrating with third parties like Supabase, Stripe or others.

### Prompt Engineering

Learn effective prompting strategies and get the most out of CodinIT.

### Custom Domain

Add your own domain to any CodinIT site app.

### Deploy

Learn how to deploy, share, and get traffic to your web applications with CodinIT.
::

## What is CodinIT

::callout{color="primary"}
**Letting Ordinary Visionaries Achieve Breakthroughs with Language-based Engineering.**

CodinIT is an AI-powered platform that lets you create and deploy apps from a single browser tab. The platform eliminates the complexity of traditional app-creation environments by combining coding, deployment, and collaboration tools in a single interface.
::

Typically, you must install programs, languages, and packages to build apps. However, on CodinIT, you can rely on AI to configure your environment so you can start building without coding experience.

The platform supports full-featured development and coding environments for those familiar with coding as well as those who are not, so there's no limit on what's possible.

### Key Features

- **Complete app generation** and setup from natural language description
- **Code suggestions** and autocomplete with AI assistance
- **Automated error detection** and debugging assistance
- **Documentation generation** for your applications
- **App deployment** to the cloud in a few clicks
- **Database integration** and hosting with Supabase native integration
- **Custom domain support** and connection

Your development environment structure will look like this:

```text
codinit-project/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îî‚îÄ‚îÄ config.json
```

## Essential Resources

::card-group
  :::card
  ---
  ariaLabel: Browse and use project templates
  icon: i-lucide-folder-open
  title: Templates
  ---
  Browse and use project templates to quickly start your next project.
  :::

  :::card
  ---
  ariaLabel: Get a full overview of how to build an app with CodinIT
  icon: i-lucide-play-circle
  title: Tutorial
  ---
  Get a full overview of how to build an app with CodinIT.
  :::

  :::card
  ---
  ariaLabel: Resolve issues in your development lifecycle
  icon: i-lucide-wrench
  title: Troubleshooting
  ---
  Resolve issues in your development lifecycle.
  :::

  :::card
  ---
  ariaLabel: Getting the Most Out of CodinIT
  icon: i-lucide-star
  title: Best Practices
  ---
  Getting the Most Out of CodinIT.
  :::

  :::card
  ---
  ariaLabel: Collaborate on your app in real time with teammates
  icon: i-lucide-users
  title: Teams
  ---
  Collaborate on your app in real time with teammates.
  :::
::

## Stay Connected

### Community & Support

::card-group
  :::card
  ---
  ariaLabel: Share ideas and let the community vote
  icon: i-lucide-lightbulb
  title: Feature Requests
  ---
  Have an idea? Share it and let the community vote
  :::

  :::card
  ---
  ariaLabel: Get help from our Community and Community Champions
  icon: i-lucide-help-circle
  title: Community Support
  ---
  Get help from our Community and Community Champions
  :::

  :::card{ariaLabel="Report a bug or an issue" icon="i-lucide-bug" title="Issues"}
  Found a bug or an issue? Let us know
  :::

  :::card
  ---
  ariaLabel: Direct support channel for paying users
  icon: i-lucide-headphones
  title: Priority Support
  ---
  Direct support channel for paying users
  :::
::

### Programs & Partnerships

::card-group
  :::card
  ---
  ariaLabel: Publish your app to get in front of thousands of people
  icon: i-lucide-rocket
  title: Launched
  ---
  Publish your app to get in front of thousands of people
  :::

  :::card
  ---
  ariaLabel: Join as an expert, or get help from our network of experts
  icon: i-lucide-handshake
  title: Partner Program
  ---
  Join as an expert, or get help from our network of experts
  :::

  :::card
  ---
  ariaLabel: Receive a 20% commission on the first 12 payments
  icon: i-lucide-percent
  title: Affiliate Program
  ---
  Receive a 20% commission on the first 12 payments
  :::
::

### Learn More about CodinIT

::card-group
  :::card
  ---
  ariaLabel: Learn more about CodinIT on our website
  icon: i-lucide-globe
  title: Visit our Website
  to: https://codinit.dev
  ---
  Explore our official website to learn more about CodinIT.
  :::

  :::card
  ---
  ariaLabel: Understand key development terms in our documentation
  icon: i-lucide-book-open
  title: Learn More
  to: https://docs.codinit.dev/getting-started/quickstart
  ---
  Familiarize yourself with key development terms by exploring our Documentation.
  :::

  :::card
  ---
  ariaLabel: prompting with codinit
  icon: i-lucide-briefcase
  title: Find out how to prompt with codinit
  to: https://codinit.dev/blog/prompting-with-codinit
  ---
  Learn how to prompt codinit for best results.
  :::

  :::card
  ---
  ariaLabel: Stay updated with the latest from the CodinIT team
  icon: i-lucide-megaphone
  title: Read Our Blog Announcements
  to: https://codinit.dev/blog
  ---
  Catch up on the latest news and updates from the CodinIT team.
  :::
::

::tip
üéâ Ready to start building? Choose your path from the Quick Start section above and begin creating your next application with CodinIT!
::


# Quickstart

Get your first CodinIT application running in under 10 minutes with this comprehensive quickstart guide.

::alert{color="green" icon="i-lucide-rocket"}
**New to CodinIT?** This guide walks you through the complete workflow from project creation to deployment.
::

## Create Your First Project

::steps{level="4"}
#### Step 1: Start a New Project

Navigate to your CodinIT dashboard and click **"Create New Project"**. Choose from:

- üì± **Mobile App** ‚Äì Responsive mobile-first applications
- üåê **Web Application** ‚Äì Full-stack web apps with backend
- üé® **Landing Page** ‚Äì Marketing sites and portfolios
- üìä **Dashboard** ‚Äì Data visualization and admin panels

#### Step 2: Describe Your App

Use natural language to describe what you want to build:

```text
Create a task management app with user authentication, 
the ability to add, edit, and delete tasks, and a 
dashboard showing task statistics.
```

#### Step 3: Review Generated Code

CodinIT will generate your complete application. Review the:

- Frontend components and styling
- Backend API endpoints
- Database schema and models
- Authentication setup

#### Step 4: Customize and Iterate

Make changes using natural language prompts or direct code editing:

```text
Add a priority system to tasks with high, medium, low options.
Style the app with a dark theme and modern card layout.
```
::

## Essential Editing Features

::card-group
  :::card{icon="i-lucide-edit" title="AI-Powered Editing"}
  Make changes using natural language prompts with instant preview
  :::

  :::card{icon="i-lucide-eye" title="Visual Editor"}
  Click and edit components directly with AI-driven visual controls
  :::

  :::card{icon="i-lucide-undo" title="Version Control"}
  Restore past versions instantly and bookmark important milestones
  :::

  :::card{icon="i-lucide-sparkles" title="Smart Suggestions"}
  Get AI suggestions for improvements and feature additions
  :::

  :::card{icon="i-lucide-image-plus" title="Media Integration"}
  Attach images and files directly to prompts for better context
  :::

  :::card{icon="i-lucide-layers" title="Component Library"}
  Access pre-built components and templates for faster development
  :::
::

## Knowledge Base Setup

Organize your project information for better AI assistance:

::steps{level="4"}
#### Step 1: Access Knowledge Base

Go to the Knowledge Base section in your dashboard.

#### Step 2: Add Project Documentation

Click "Add Entry" and categorize information under:

- üìå **Project Overview** ‚Äì Define objectives and scope
- üöÄ **Key Features** ‚Äì List core functionalities
- üé® **Design Guidelines** ‚Äì Document UI/UX principles
- üîß **Technical Requirements** ‚Äì Specify technologies and constraints

#### Step 3: Keep Information Current

Regularly review and update entries as your project evolves to ensure development stays aligned with your vision.
::

## Add Backend Capabilities

### Connect with Supabase

Supabase integration provides powerful backend capabilities with minimal setup:

::steps{level="4"}
#### Step 1: Create Supabase Project

Create an account on [Supabase](https://supabase.com){ariaLabel="Supabase Website" rel="nofollow"} and set up a new project.

#### Step 2: Link to CodinIT

In CodinIT, navigate to Settings ‚Üí Connect Supabase and follow the integration steps.

#### Step 3: Configure Data Models

Set up database tables, manage user data, and configure real-time subscriptions.

#### Step 4: Enable Authentication

Configure user authentication flows including email verification and social logins.
::

### Authentication Implementation

::tabs
  :::div{label="Setup Process"}
  **Step 1: Supabase Account Creation**
  
  Visit Supabase and sign up to access the project dashboard.
  
  **Step 2: Integration Configuration**
  
  Input your Supabase project URL and API keys to establish connection.
  
  **Step 3: Authentication Forms**
  
  Use CodinIT's AI form builder to create intuitive login and registration forms.
  
  **Step 4: Workflow Implementation**
  
  Set up Supabase Edge Functions for token validation and session management.
  :::

  :::div{label="Advanced Features"}
  **Email Verification**
  
  Configure automated email verification upon user registration.
  
  **Social Authentication**
  
  Enable Google, GitHub, and other OAuth provider integrations.
  
  **Role-Based Access**
  
  Implement user roles and permissions for secure access control.
  
  **Session Management**
  
  Handle user sessions with automatic refresh and secure logout.
  :::
::

## Testing and Deployment

### Preview Your Application

::alert{color="blue" icon="i-lucide-monitor"}
**Live Preview** - Every change is instantly reflected in the preview pane, allowing you to test functionality in real-time.
::

- **Responsive Testing** ‚Äì Check how your app looks on different device sizes
- **Feature Testing** ‚Äì Test user flows and interactions
- **Performance Monitoring** ‚Äì Monitor loading times and responsiveness

### Deploy to Production

::steps{level="3"}
### Step 1: Pre-Deployment Check

Review your application for:

- Functionality completeness
- Responsive design across devices
- Performance optimization
- Error handling

### Step 2: Choose Deployment Option

Select from multiple deployment options:

- **CodinIT Hosting** ‚Äì Instant deployment with custom domain support
- **GitHub Integration** ‚Äì Deploy via GitHub Pages or other CI/CD platforms
- **Custom Hosting** ‚Äì Export code for deployment anywhere

### Step 3: Configure Custom Domain

Add your custom domain for professional deployment:

- Point your domain to CodinIT's servers
- Configure SSL certificates automatically
- Set up redirect rules and routing
::

## Next Steps

::card-group
  :::card
  ---
  ariaLabel: Learn about team collaboration features
  icon: i-lucide-users
  title: Team Collaboration
  to: https://docs.codinit.dev/getting-started/teams
  ---
  Invite team members and collaborate in real-time
  :::

  :::card
  ---
  ariaLabel: Connect with third-party services and APIs
  icon: i-lucide-puzzle
  title: Integrations
  to: https://docs.codinit.dev/integrations/github
  ---
  Connect with third-party services and APIs
  :::

  :::card
  ---
  ariaLabel: Explore framework-specific development resources
  icon: i-lucide-code
  title: Developer Tools
  to: https://docs.codinit.dev/getting-started/developer-docs
  ---
  Explore framework-specific development resources
  :::
::

::tip
üéâ **Congratulations!** You've completed the quickstart guide. Your application is ready for further development and customization. Explore the advanced features to build even more powerful applications.
::


# Teams

CodinIT lets you build apps together, live. Invite your designer, developer, agency, or anyone else to your workspace. Everyone sees changes as they happen in real-time.

::callout{color="blue" icon="i-lucide-users"}
**Collaborative Development** - Experience seamless team collaboration with real-time editing, shared workspaces, and professional project management tools.
::

## Workspace Plans

Each subscription connects to a workspace with different collaboration capabilities:

::card-group
  :::card{color="primary" icon="i-lucide-user" title="Pro Subscription"}
  Personal workspaces with up to 2 collaborators per project. Collaborators use project owner credits for seamless cost management.
  :::

  :::card{color="green" icon="i-lucide-users" title="Teams Subscription"}
  Up to 20 users in workspace. Owners & admins manage users and projects. Shared credit pool for all team members.
  :::
::

## Workspace Management

### Create a Workspace

A workspace is your shared environment for building and collaborating on projects with your team.

::steps{level="3"}
### Step 1: Create New Workspace

Click **"Create new workspace"** from the dashboard or any existing project.

### Step 2: Name Your Workspace

Choose a descriptive name for your workspace that reflects your team or organization.

### Step 3: Choose a Plan

Select a subscription plan that fits your team size and collaboration requirements.
::

### Rename a Workspace

::steps{level="3"}
### Step 1: Switch to Workspace

Ensure you're in the correct workspace (switch if needed from the sidebar).

### Step 2: Access Settings

Navigate to **Settings** from your workspace dashboard.

### Step 3: Edit Details

Update the **Workspace name** and **description** to reflect changes in your team or project focus.
::

## Team Member Management

### Invite & Manage Collaborators

::steps{level="3"}
### Step 1: Upgrade Your Plan

Upgrade to the **Teams** tier if you're currently on a personal plan.

### Step 2: Send Invitations

Click **"Invite"** in a project or from the main dashboard to access the invitation system.

### Step 3: Add Team Members

Enter email addresses to send invitations to your team members and collaborators.

### Step 4: Team Integration

When invitations are accepted, members join your workspace and gain access to all shared projects.
::

### Role-Based Permissions

Different roles provide varying levels of access and control within your workspace:

| Action                                          | Owner | Admin | Editor |
| ----------------------------------------------- | ----- | ----- | ------ |
| Edit projects                                   | ‚úì     | ‚úì     | ‚úì      |
| Publish projects                                | ‚úì     | ‚úì     | ‚úì      |
| Connect/disconnect Supabase org to workspace    | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect Supabase project to projects | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub org to workspace      | ‚úì     | ‚úì     | ‚úó      |
| Connect/disconnect GitHub repo to projects      | ‚úì     | ‚úì     | ‚úó      |
| Invite project-level collaborators              | ‚úì     | ‚úì     | ‚úó      |
| Transfer projects to other workspaces           | ‚úì     | ‚úì     | ‚úó      |
| Set roles for other users                       | ‚úì     | ‚úì     | ‚úó      |

### Role Descriptions

::field-group
  :::field{name="Owner" type="role"}
  Complete administrative control over the workspace, billing management, and all projects
  :::

  :::field{name="Admin" type="role"}
  Can manage most workspace and project aspects, but cannot modify other admin roles
  :::

  :::field{name="Editor" type="role"}
  Can edit and publish projects but cannot manage workspace settings, integrations, or user permissions
  :::
::

## Real-Time Collaboration Features

Once team members join your workspace, experience seamless real-time collaboration:

::card-group
  :::card
  ---
  ariaLabel: See team member cursors and live changes in real-time
  icon: i-lucide-mouse-pointer
  title: Live Cursors
  ---
  See team member cursors and live changes as they work in real-time
  :::

  :::card
  ---
  ariaLabel: Icons show who's currently online and active
  icon: i-lucide-circle-dot
  title: Team Presence
  ---
  Icons in top-right corner show who's currently online and active
  :::

  :::card
  ---
  ariaLabel: Edit any element together with immediate synchronization
  icon: i-lucide-edit
  title: Instant Editing
  ---
  Edit any element together with immediate synchronization across all users
  :::

  :::card
  ---
  ariaLabel: All modifications reflected immediately across all team members' screens
  icon: i-lucide-refresh-cw
  title: Change Synchronization
  ---
  All modifications reflected immediately across all team members' screens
  :::
::


# Developer Docs

Framework-focused prompting strategies and development patterns for building applications with CodinIT. Each section provides proven patterns, best practices, and ready-to-use prompts tailored to specific technology stacks.

::callout{color="blue" icon="i-heroicons-code-bracket"}
**Framework-Focused Prompts** - Specialized prompt patterns for Next.js, Python, Gradio, and Streamlit development. Copy, modify, and use these templates to build better applications faster.
::

## Overview

This library provides targeted prompting strategies for specific development frameworks. Each section contains proven patterns, best practices, and ready-to-use prompts tailored to the unique characteristics of each technology stack.

::alert{color="green" icon="i-heroicons-light-bulb"}
**Pro Tip** - These prompts are designed to work with any AI coding assistant. Adapt the examples to your specific project needs and requirements.
::

## Supported Frameworks

::card-group{cols="2"}
  :::card
  ---
  ariaLabel: Learn about Next.js Development
  icon: i-simple-icons-nextdotjs
  title: Next.js Development
  ---
  Full-stack React framework with SSR, API routes, and modern tooling for web applications.
  
  :badge[React]{color="blue" variant="outline"} :badge[TypeScript]{color="blue" variant="outline"} :badge[Full-Stack]{color="green" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Python Development
  icon: i-simple-icons-python
  title: Python Development
  ---
  Backend services, data processing, and general-purpose application development.
  
  :badge[Backend]{color="orange" variant="outline"} :badge[Data Science]{color="purple" variant="outline"} :badge[APIs]{color="emerald" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Gradio Development
  icon: i-heroicons-chart-bar
  title: Gradio Development
  ---
  Rapid ML model deployment and interactive data science applications.
  
  :badge[ML/AI]{color="red" variant="outline"} :badge[Interactive]{color="cyan" variant="outline"} :badge[Prototyping]{color="amber" variant="outline"}
  :::

  :::card
  ---
  ariaLabel: Learn about Streamlit Development
  icon: i-heroicons-presentation-chart-line
  title: Streamlit Development
  ---
  Data apps and dashboards with Python-first development approach.
  
  :badge[Data Apps]{color="indigo" variant="outline"} :badge[Dashboards]{color="pink" variant="outline"} :badge[Analytics]{color="teal" variant="outline"}
  :::
::

---

## Next.js Development

::callout{color="black" icon="i-simple-icons-nextdotjs"}
**Modern React framework with server-side rendering, API routes, and performance optimization.**
::

### Project Setup & Architecture

::tabs
  :::div{label="New Project Setup"}
  ```markdown
  Create a new Next.js 14 application with the following specifications:
  
  **Tech Stack:**
  - Next.js 14 with App Router
  - TypeScript for type safety
  - Tailwind CSS for styling
  - Prisma with PostgreSQL for database
  - NextAuth.js for authentication
  
  **Project Structure:**
  - `/app` directory structure with proper layouts
  - `/components` for reusable UI components
  - `/lib` for utilities and database configuration
  - `/types` for TypeScript definitions
  
  **Initial Features:**
  - Landing page with hero section and navigation
  - User authentication (sign up, login, logout)
  - Protected dashboard route
  - Responsive design with dark mode support
  
  Set up the basic project structure and create placeholder components.
  ```
  :::

  :::div{label="Component Architecture"}
  ```markdown
  Design a component architecture for a [describe app type] application:
  
  **Component Categories:**
  - UI components (buttons, inputs, cards)
  - Layout components (header, sidebar, footer)
  - Feature components (user profile, product listing)
  - Page components (home, dashboard, settings)
  
  **Requirements:**
  - TypeScript interfaces for all props
  - Compound component patterns where appropriate
  - Accessibility features (ARIA labels, keyboard navigation)
  - Consistent styling with Tailwind CSS variants
  
  Include examples of 2-3 components with proper TypeScript typing.
  ```
  :::
::

---

## Python Development

::callout{color="yellow" icon="i-simple-icons-python"}
**Versatile language for backend development, data processing, and API creation.**
::

### API Development

::tabs
  :::div{label="FastAPI Setup"}
  ```markdown
  Create a FastAPI application with the following requirements:
  
  **Features:**
  - RESTful API with CRUD operations
  - User authentication with JWT tokens
  - Database integration with SQLAlchemy
  - Input validation with Pydantic
  - Automated API documentation
  
  **Structure:**
  - `/models` for database models
  - `/routers` for API endpoints
  - `/schemas` for Pydantic models
  - `/auth` for authentication logic
  
  Include user registration, login, and protected endpoints.
  ```
  :::

  :::div{label="Data Processing"}
  ```markdown
  Build a data processing pipeline that:
  
  **Input Sources:**
  - CSV files from uploads
  - Database queries
  - API endpoints
  
  **Processing Steps:**
  - Data cleaning and validation
  - Statistical analysis
  - Visualization generation
  - Export to multiple formats
  
  **Output:**
  - Processed datasets
  - Summary statistics
  - Interactive charts
  - Automated reports
  
  Use pandas, numpy, and plotly for implementation.
  ```
  :::
::

---

## Gradio Development

::callout{color="red" icon="i-heroicons-chart-bar"}
**Rapid prototyping framework for ML models and interactive demos.**
::

### Interactive ML Applications

::tabs
  :::div{label="Model Demo Interface"}
  ```markdown
  Create a Gradio interface for [ML model type]:
  
  **Interface Components:**
  - File upload for input data
  - Parameter sliders for model tuning
  - Real-time prediction display
  - Confidence scores and explanations
  - Download results functionality
  
  **Features:**
  - Batch processing capabilities
  - Model comparison tools
  - Performance metrics display
  - Error handling and validation
  
  Include examples with sample data and clear instructions.
  ```
  :::

  :::div{label="Data Visualization Dashboard"}
  ```markdown
  Build a Gradio dashboard for data exploration:
  
  **Components:**
  - Dataset upload and preview
  - Interactive charts and plots
  - Statistical summary tables
  - Filter and search capabilities
  - Export functionality
  
  **Visualizations:**
  - Distribution plots
  - Correlation matrices
  - Time series analysis
  - Geographic mapping (if applicable)
  
  Make it responsive and user-friendly for non-technical users.
  ```
  :::
::

---

## Streamlit Development

::callout{color="red" icon="i-heroicons-presentation-chart-line"}
**Python-first framework for building data applications and interactive dashboards.**
::

### Data Dashboards

::tabs
  :::div{label="Analytics Dashboard"}
  ```markdown
  Create a comprehensive analytics dashboard using Streamlit:
  
  **Data Sources:**
  - Multiple data source connections (CSV, database, API)
  - Real-time data refresh capabilities
  - Data caching for performance
  - Error handling for data loading
  
  **Dashboard Layout:**
  - Multi-page application structure
  - Sidebar navigation and filters
  - Responsive grid layout
  - Customizable date ranges
  - Export functionality
  
  **Visualizations:**
  - KPI metrics with st.metric()
  - Interactive charts with Plotly
  - Data tables with filtering/sorting
  - Geographic visualizations
  
  Include caching and performance optimization.
  ```
  :::

  :::div{label="Machine Learning App"}
  ```markdown
  Build a complete ML application with Streamlit:
  
  **Features:**
  - Model training interface
  - Hyperparameter tuning
  - Performance evaluation
  - Prediction interface
  - Model deployment options
  
  **Components:**
  - Data upload and preprocessing
  - Model selection and training
  - Results visualization
  - Model comparison tools
  - Export trained models
  
  Include proper error handling and user guidance.
  ```
  :::
::

---

## Development Best Practices

::alert{color="amber" icon="i-heroicons-star"}
**Quality Assurance** - Follow these practices for professional-grade applications regardless of framework choice.
::

### Code Quality Guidelines

::steps{level="4"}
#### Step 1: Planning & Design

Start with clear requirements and architecture design before implementation.

#### Step 2: Iterative Development

Build features incrementally with regular testing and validation.

#### Step 3: Code Review

Implement peer review processes for maintaining code quality standards.

#### Step 4: Deployment & Monitoring

Set up automated deployment with proper monitoring and error tracking.
::

### Framework Selection Guide

Choose the right framework based on your project requirements:

| Framework     | Best For            | Use Cases                         |
| ------------- | ------------------- | --------------------------------- |
| **Next.js**   | Full-stack web apps | E-commerce, SaaS, Marketing sites |
| **Python**    | Backend services    | APIs, Data processing, Automation |
| **Gradio**    | ML demos            | Model prototyping, Research demos |
| **Streamlit** | Data applications   | Analytics dashboards, BI tools    |

## Getting Started

::alert{color="green" icon="i-heroicons-rocket-launch"}
**Ready to start building?** Choose your framework and begin with the appropriate prompt templates. Remember to adapt these examples to your specific project needs.
::

### Quick Start Checklist

::list{icon="i-heroicons-check"}
- Identify your project requirements and constraints
- Choose the appropriate framework for your use case
- Start with a basic project setup prompt
- Iterate with specific feature implementation prompts
- Apply best practices for code quality and security
- Set up proper testing and deployment workflows
::

::card
---
color: blue
icon: i-heroicons-chat-bubble-left-right
title: Need Help?
---
These prompts are starting points. Feel free to modify them based on your specific requirements, and don't hesitate to break complex tasks into smaller, more manageable prompts.

**Pro Tip:** Combine multiple prompts for complex applications, building one feature at a time.
::


# GitHub

Import your existing GitHub repositories into CodinIT to leverage AI-powered development on your current codebase.

::callout{icon="i-simple-icons-github"}
**Import Existing Code:** Connect your GitHub repositories to CodinIT for AI-enhanced development of existing projects.
::

## Why Import GitHub Repositories?

::card-group
  :::card{icon="i-lucide-code" title="Leverage Existing Code"}
  Build upon your existing codebase with AI assistance instead of starting from scratch.
  :::

  :::card{icon="i-lucide-zap" title="Modernize Legacy Apps"}
  Add new features to older projects using modern AI development techniques.
  :::

  :::card{icon="i-lucide-users" title="Team Transition"}
  Gradually migrate team workflows to AI-assisted development.
  :::

  :::card{icon="i-lucide-git-branch" title="Maintain History"}
  Preserve complete git history while adding AI development capabilities.
  :::
::

## Supported Repository Types

CodinIT can import and enhance various types of GitHub repositories:

::tabs
  :::div{label="Web Applications"}
  **Frontend and full-stack applications:**
  
  - **React/Next.js** - Add new components and features with AI assistance.
  - **Vue/Nuxt** - Enhance existing applications with AI-generated code.
  - **Angular** - Modernize components and add intelligent features.
  - **Vanilla JavaScript** - Upgrade to modern frameworks with AI guidance.
  :::

  :::div{label="Backend Services"}
  **APIs and server applications:**
  
  - **Node.js/Express** - Add new endpoints and business logic.
  - **Python/Django** - Enhance data processing and API capabilities.
  - **PHP/Laravel** - Modernize legacy PHP applications.
  - **Ruby/Rails** - Add new features to existing Rails apps.
  :::

  :::div{label="Data & Analytics"}
  **Data processing and analysis projects:**
  
  - **Python Data Science** - Enhance analysis with AI-generated insights.
  - **Jupyter Notebooks** - Add interactive features and visualizations.
  - **R Projects** - Integrate modern web interfaces.
  - **SQL Databases** - Generate query optimization and reporting features.
  :::
::

## Repository Import Process

::steps
### Connect GitHub Account

Authorize CodinIT to access your GitHub repositories in your settings.

### Choose Repository to Import

Select the public or private GitHub repository you want to enhance with AI development.

### Configure AI Model

Choose the AI provider that best fits your project needs.

### Import and Analyze

CodinIT will analyze your codebase and prepare it for AI-enhanced development.
::

## Post-Import Development

Once imported, use AI to understand your codebase, add new features, and modernize your application.

::collapsible{title="Feature Enhancement Examples"}
**Add Authentication to Existing App:**

```text
Add user authentication to this application:
- User registration and login pages
- Protected routes and middleware
- Session management
- Password reset functionality
- Integration with existing database schema
```

**Modernize UI Components:**

```text
Modernize the user interface:
- Convert existing components to modern design system
- Add responsive design for mobile compatibility
- Implement dark mode support
- Improve accessibility features
```

**Add API Endpoints:**

```text
Add new API functionality:
- RESTful endpoints for data management
- Input validation and error handling
- Database integration with existing schema
- API documentation and testing
```
::

## Best Practices for Repository Import

### Pre-Import Preparation

::checklist
- Clean up unused files and dependencies.
- Ensure repository has clear folder structure.
- Add basic README with project description.
- Remove sensitive data and API keys.
- Create main branch with stable code.
::

### Post-Import Optimization

::tabs
  :::div{label="Code Organization"}
  **Organize code for better AI understanding:**
  
  - Use descriptive file and folder names.
  - Add comments explaining complex business logic.
  - Separate concerns into logical modules.
  - Maintain consistent coding style throughout.
  :::

  :::div{label="AI Prompting"}
  **Write effective prompts for existing codebases:**
  
  - Reference specific files and functions in prompts.
  - Explain existing patterns to maintain consistency.
  - Ask for incremental improvements rather than rewrites.
  - Use AI to understand code before making changes.
  :::
::


# Plugins

Connect CodinIT with your favorite tools and services to build production-ready applications faster. From version control to databases, deployment platforms, and AI providers.

::callout{icon="i-heroicons-information-circle"}
**Integration Philosophy:** CodinIT.dev is designed to work with your existing development ecosystem, not replace it. These integrations ensure you maintain full control over your codebase while leveraging AI-powered development tools.
::

## Database Integrations

::tabs
  :::div{label="SQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-postgresql" title="PostgreSQL"}
      Industry-standard relational database with advanced features, JSON support, and excellent performance.
      :::::
    
      :::::card{icon="i-simple-icons-mysql" title="MySQL"}
      Popular open-source relational database known for reliability and ease of use.
      :::::
    
      :::::card{icon="i-simple-icons-sqlite" title="SQLite"}
      Lightweight, file-based SQL database perfect for development and small applications.
      :::::
    
      :::::card{icon="i-lucide-database" title="Microsoft SQL Server"}
      Enterprise-grade database with advanced analytics and business intelligence features.
      :::::
    ::::
  :::

  :::div{label="NoSQL Databases"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-mongodb" title="MongoDB"}
      Document-oriented database with flexible schema and horizontal scaling capabilities.
      :::::
    
      :::::card{icon="i-simple-icons-redis" title="Redis"}
      In-memory data structure store used as database, cache, and message broker.
      :::::
    
      :::::card{icon="i-lucide-database" title="CouchDB"}
      Document database with multi-master replication and web-based administration.
      :::::
    
      :::::card{icon="i-lucide-layers" title="DynamoDB"}
      Amazon's managed NoSQL database service with automatic scaling and high availability.
      :::::
    ::::
  :::

  :::div{label="Cloud Database Services"}
    ::::card-group{cols="2"}
      :::::card{icon="i-simple-icons-supabase" title="Supabase"}
      Open-source Firebase alternative with PostgreSQL, real-time subscriptions, and built-in authentication.
      :::::
    
      :::::card{icon="i-simple-icons-firebase" title="Firebase"}
      Google's mobile and web application development platform with real-time database and hosting.
      :::::
    
      :::::card{icon="i-simple-icons-planetscale" title="PlanetScale"}
      Serverless MySQL platform with branching, schema migrations, and automatic scaling.
      :::::
    
      :::::card{icon="i-lucide-database" title="Neon"}
      Serverless PostgreSQL with automatic scaling, branching, and point-in-time recovery.
      :::::
    ::::
  :::
::

## AI Model Providers

::card-group{cols="2"}
  :::card{icon="i-lucide-brain" title="Anthropic Claude"}
  Advanced reasoning capabilities with Claude 4 Sonnet and other models for sophisticated code generation and problem-solving.
  :::

  :::card{icon="i-lucide-bot" title="OpenAI GPT"}
  Industry-leading language models including GPT-4, GPT-4 Turbo, and o1 for intelligent app development.
  :::

  :::card{icon="i-lucide-sparkles" title="Google Gemini"}
  Google's multimodal AI with Gemini Pro and Flash models for fast and efficient development.
  :::

  :::card{icon="i-lucide-server" title="Local Models (Ollama)"}
  Run AI models locally for privacy, offline development, and cost control.
  :::
::

## Deployment Platforms

::card-group{cols="2"}
  :::card{icon="i-simple-icons-vercel" title="Vercel"}
  Optimized for modern frontend frameworks with automatic deployments and edge computing.
  :::

  :::card{icon="i-simple-icons-netlify" title="Netlify"}
  All-in-one platform for web projects with forms, functions, and identity management.
  :::

  :::card{icon="i-simple-icons-amazonaws" title="AWS"}
  Comprehensive cloud platform with extensive services for any application size.
  :::

  :::card{icon="i-simple-icons-googlecloud" title="Google Cloud"}
  Google's cloud platform with AI/ML services and global infrastructure.
  :::
::

## Authentication & Security

::card-group{cols="2"}
  :::card{icon="i-simple-icons-auth0" title="Auth0"}
  Enterprise identity platform with social logins, multi-factor authentication, and compliance features.
  :::

  :::card{icon="i-simple-icons-firebase" title="Firebase Auth"}
  Google's authentication service with social providers and email/password authentication.
  :::

  :::card{icon="i-simple-icons-supabase" title="Supabase Auth"}
  Open-source authentication with built-in database integration and social providers.
  :::

  :::card{icon="i-lucide-key" title="NextAuth.js"}
  Open-source authentication library for Next.js applications with multiple provider support.
  :::
::

## Payment Processing

::card-group{cols="2"}
  :::card{icon="i-simple-icons-stripe" title="Stripe"}
  Industry-leading payment platform with comprehensive APIs and global coverage.
  :::

  :::card{icon="i-simple-icons-paypal" title="PayPal"}
  Global payment platform with buyer protection and multiple payment methods.
  :::
::

## Communication & Notifications

::card-group{cols="2"}
  :::card{icon="i-lucide-mail" title="Resend"}
  Developer-first email API with excellent deliverability and React email templates.
  :::

  :::card{icon="i-simple-icons-mailgun" title="Mailgun"}
  Powerful email API for developers with advanced routing and analytics.
  :::
::

## Analytics & Monitoring

::card-group{cols="2"}
  :::card{icon="i-simple-icons-googleanalytics" title="Google Analytics"}
  Comprehensive web analytics platform with audience insights and conversion tracking.
  :::

  :::card{icon="i-lucide-activity" title="Umami"}
  Privacy-focused, open-source web analytics alternative to Google Analytics.
  :::
::


# Anthropic

> Learn how to configure and use Anthropic Claude models with CodinIT.dev. Covers API key setup, model selection, and advanced features like prompt caching.

**Website:** <https://www.anthropic.com/>{ariaLabel="Anthropic Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [Anthropic Console](https://console.anthropic.com/){ariaLabel="Anthropic Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the [API keys](https://console.anthropic.com/settings/keys){ariaLabel="Anthropic API Keys Settings" rel="nofollow"} section.
3. **Create a Key:** Click "Create Key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following Anthropic Claude models:

- `claude-opus-4-20250514`
- `claude-opus-4-20250514:thinking` (Extended Thinking variant)
- `claude-sonnet-4-20250514` (Recommended)
- `claude-sonnet-4-20250514:thinking` (Extended Thinking variant)
- `claude-3-7-sonnet-20250219`
- `claude-3-7-sonnet-20250219:thinking` (Extended Thinking variant)
- `claude-3-5-sonnet-20241022`
- `claude-3-5-haiku-20241022`
- `claude-3-opus-20240229`
- `claude-3-haiku-20240307`

See [Anthropic's Model Documentation](https://docs.anthropic.com/en/docs/about-claude/models){ariaLabel="Anthropic Model Documentation" rel="nofollow"} for more details on each model's capabilities.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "Anthropic" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your Anthropic API key into the "Anthropic API Key" field.
4. **Select Model:** Choose your desired Claude model from the "Model" dropdown.
5. **(Optional) Custom Base URL:** If you need to use a custom base URL for the Anthropic API, check "Use custom base URL" and enter the URL. Most users won't need to adjust this setting.

### Extended Thinking

Anthropic models offer an "Extended Thinking" feature, designed to give them enhanced reasoning capabilities for complex tasks. This feature allows the model to output its step-by-step thought process before delivering a final answer, providing transparency and enabling more thorough analysis for challenging prompts.

When extended thinking is in CodinIT.dev, the model generates `thinking` content blocks that detail its internal reasoning. These insights are then incorporated into its final response.
CodinIT.dev users can leverage this by checking the `Enable Extended Thinking` box below the model selection menu after selecting a Claude Model from any provider.

**Key Aspects of Extended Thinking:**

- **Supported Models:** This feature is available for select models, including variants of Claude Opus 4, Claude Sonnet 4, and Claude Sonnet 3.7. The specific models listed in the "Supported Models" section above with the `:thinking` suffix are pre-configured in CodinIT.dev to utilize this.
- **Summarized Thinking (Claude 4):** For Claude 4 models, the API returns a summary of the full thinking process to balance insight with efficiency and prevent misuse. You are billed for the full thinking tokens, not just the summary.
- **Streaming:** Extended thinking responses, including the `thinking` blocks, can be streamed.
- **Tool Use & Prompt Caching:** Extended thinking interacts with tool use (requiring thinking blocks to be passed back) and prompt caching (with specific behaviors around cache invalidation and context).

For comprehensive details on how extended thinking works, including API examples, interaction with tool use, prompt caching, and pricing, please refer to the [official Anthropic documentation on Extended Thinking](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking){ariaLabel="Anthropic Extended Thinking Documentation" rel="nofollow"}.

### Tips and Notes

- **Prompt Caching:** Claude 3 models support [prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching){ariaLabel="Anthropic Prompt Caching Documentation" rel="nofollow"}, which can significantly reduce costs and latency for repeated prompts.
- **Context Window:** Claude models have large context windows (200,000 tokens), allowing you to include a significant amount of code and context in your prompts.
- **Pricing:** Refer to the [Anthropic Pricing](https://www.anthropic.com/pricing){ariaLabel="Anthropic Pricing Page" rel="nofollow"} page for the latest pricing information.
- **Rate Limits:** Anthropic has strict rate limits based on [usage tiers](https://docs.anthropic.com/en/api/rate-limits#requirements-to-advance-tier){ariaLabel="Anthropic API Rate Limits Documentation" rel="nofollow"}.


# DeepSeek

> Learn how to configure and use DeepSeek models like deepseek-chat and deepseek-reasoner with CodinIT.dev.

CodinIT.dev supports accessing models through the DeepSeek API, including `deepseek-chat` and `deepseek-reasoner`.

**Website:** <https://platform.deepseek.com/>{ariaLabel="DeepSeek Platform Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [DeepSeek Platform](https://platform.deepseek.com/){ariaLabel="DeepSeek Platform" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Find your API keys in the [API keys](https://platform.deepseek.com/api_keys){ariaLabel="DeepSeek API Keys Section" rel="nofollow"} section of the platform.
3. **Create a Key:** Click "Create new API key". Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following DeepSeek models:

- `deepseek-v3-0324` (Recommended for coding tasks)
- `deepseek-r1` (Recommended for reasoning tasks)

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the ‚öôÔ∏è icon in the CodinIT.dev panel.
2. **Select Provider:** Choose "DeepSeek" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your DeepSeek API key into the "DeepSeek API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown.

### Tips and Notes

- **Pricing:** Refer to the [DeepSeek Pricing](https://api-docs.deepseek.com/quick_start/pricing/){ariaLabel="DeepSeek Pricing Page" rel="nofollow"} page for details on model costs.


# Google Gemini

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){ariaLabel="Learn more about GCP Vertex AI" rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){ariaLabel="Google Cloud Console" rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){ariaLabel="GCP Vertex AI Access Control documentation" rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){ariaLabel="Download Visual Studio Code" rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){ariaLabel="Google Cloud CLI installation guide" rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){ariaLabel="GCP IAM Best Practices" rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics suchs as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){ariaLabel="Learn more about GCP Vertex AI Quotas" rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){ariaLabel="GCP Vertex AI Documentation" rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# xAI Groq

> Learn how to configure and use xAI's Grok models with CodinIT.dev, including API key setup, supported models, and reasoning capabilities.

xAI is the company behind Grok, a large language model known for its conversational abilities and large context window. Grok models are designed to provide helpful, informative, and contextually relevant responses.

**Website:** <https://x.ai/>{ariaLabel="xAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Go to the [xAI Console](https://console.x.ai/){ariaLabel="xAI Console" rel="nofollow"}. Create an account or sign in.
2. **Navigate to API Keys:** Go to the API keys section in your dashboard.
3. **Create a Key:** Click to create a new API key. Give your key a descriptive name (e.g., "CodinIT.dev").
4. **Copy the Key:** &#x2A;*Important:** Copy the API key *immediately*. You will not be able to see it again. Store it securely.

### Supported Models

CodinIT.dev supports the following xAI Grok models:

#### Grok-3 Models

- `grok-3-beta` (Default) - xAI's Grok-3 beta model with 131K context window
- `grok-3-fast-beta` - xAI's Grok-3 fast beta model with 131K context window
- `grok-3-mini-beta` - xAI's Grok-3 mini beta model with 131K context window
- `grok-3-mini-fast-beta` - xAI's Grok-3 mini fast beta model with 131K context window

#### Grok-2 Models

- `grok-2-latest` - xAI's Grok-2 model - latest version with 131K context window
- `grok-2` - xAI's Grok-2 model with 131K context window
- `grok-2-1212` - xAI's Grok-2 model (version 1212) with 131K context window

#### Grok Vision Models

- `grok-2-vision-latest` - xAI's Grok-2 Vision model - latest version with image support and 32K context window
- `grok-2-vision` - xAI's Grok-2 Vision model with image support and 32K context window
- `grok-2-vision-1212` - xAI's Grok-2 Vision model (version 1212) with image support and 32K context window
- `grok-vision-beta` - xAI's Grok Vision Beta model with image support and 8K context window

#### Legacy Models

- `grok-beta` - xAI's Grok Beta model (legacy) with 131K context window

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "xAI" from the "API Provider" dropdown.
3. **Enter API Key:** Paste your xAI API key into the "xAI API Key" field.
4. **Select Model:** Choose your desired Grok model from the "Model" dropdown.

### Reasoning Capabilities

Grok 3 Mini models feature specialized reasoning capabilities, allowing them to "think before responding" - particularly useful for complex problem-solving tasks.

#### Reasoning-Enabled Models

Reasoning is only supported by:

- `grok-3-mini-beta`
- `grok-3-mini-fast-beta`

The Grok 3 models `grok-3-beta` and `grok-3-fast-beta` do not support reasoning.

#### Controlling Reasoning Effort

When using reasoning-enabled models, you can control how hard the model thinks with the `reasoning_effort` parameter:

- `low`: Minimal thinking time, using fewer tokens for quick responses
- `high`: Maximum thinking time, leveraging more tokens for complex problems

Choose `low` for simple queries that should complete quickly, and `high` for harder problems where response latency is less important.

#### Key Features

- **Step-by-Step Problem Solving**: The model thinks through problems methodically before delivering an answer
- **Math & Quantitative Strength**: Excels at numerical challenges and logic puzzles
- **Reasoning Trace Access**: The model's thinking process is available via the `reasoning_content` field in the response completion object

### Tips and Notes

- **Context Window:** Most Grok models feature large context windows (up to 131K tokens), allowing you to include substantial amounts of code and context in your prompts.
- **Vision Capabilities:** Select vision-enabled models (`grok-2-vision-latest`, `grok-2-vision`, etc.) when you need to process or analyze images.
- **Pricing:** Pricing varies by model, with input costs ranging from $0.3 to $5.0 per million tokens and output costs from $0.5 to $25.0 per million tokens. Refer to the xAI documentation for the most current pricing information.
- **Performance Tradeoffs:** "Fast" variants typically offer quicker response times but may have higher costs, while "mini" variants are more economical but may have reduced capabilities.


# Mistral

Connect Mistral AI's sophisticated models to CodinIT.dev for precise, efficient app development.

::callout{icon="i-lucide-sparkles"}
**Mistral AI Precision** - Experience French AI excellence with Mistral's models known for precise instruction following, exceptional coding capabilities, and efficient performance.
::

## Why Choose Mistral for Development?

::card-group
  :::card{icon="i-lucide-code" title="Coding Specialist"}
  Codestral model specifically designed for software development tasks.
  :::

  :::card{icon="i-lucide-target" title="Precise Instructions"}
  Exceptional accuracy in following detailed technical specifications.
  :::

  :::card{icon="i-lucide-zap" title="Efficient Performance"}
  High-quality outputs with optimized token usage and speed.
  :::

  :::card{icon="i-lucide-globe" title="Multilingual Excellence"}
  Superior support for multiple programming languages and human languages.
  :::
::

## Available Mistral Models

| Model             | Type    | Strengths           | Best For             | Context |
| ----------------- | ------- | ------------------- | -------------------- | ------- |
| **Mistral Large** | General | Advanced reasoning  | Complex applications | 128k    |
| **Codestral**     | Coding  | Code specialization | Software development | 32k     |
| **Mixtral 8x7b**  | General | High throughput     | High-volume usage    | 32k     |
| **Mistral 7b**    | General | Fast responses      | Quick iterations     | 32k     |

## API Key Setup

::steps
### Create Mistral Account

Visit [Mistral Console](https://console.mistral.ai/){ariaLabel="Mistral Console" rel="nofollow"} and create your developer account.

### Generate API Key

Navigate to the API Keys section and create a new key.

### Secure Key Storage

Store your API key securely in your project's environment variables.
::

## CodinIT Configuration

To configure the Mistral provider in CodinIT, navigate to your project settings, select "Mistral" from the AI Provider dropdown, and enter your API key.

## Development Examples

### Full-Stack Application Development

```typescript
// Example: E-commerce platform with Codestral
const prompt = `
Create a complete e-commerce platform using Next.js and TypeScript:
- Product catalog with search and filtering
- Shopping cart with persistent state
- User authentication and profiles
`;
```

### API Development

```python
# Example: Microservices with FastAPI
prompt = """
Design a microservices architecture for a content management system:
- User service with OAuth integration
- Content service with version control
- Media service with CDN integration
"""
```

## Best Practices

### Prompt Engineering

::card-group
  :::card{icon="i-lucide-list" title="Detailed Specifications"}
  Provide comprehensive requirements and technical constraints.
  :::

  :::card{icon="i-lucide-layers" title="Structured Context"}
  Organize information clearly with priorities and dependencies.
  :::

  :::card{icon="i-lucide-code" title="Code Context"}
  Include relevant existing code patterns and architecture.
  :::

  :::card{icon="i-lucide-refresh-cw" title="Iterative Refinement"}
  Build complex features incrementally with feedback loops.
  :::
::

## Troubleshooting Guide

### Common Issues

::accordion
  :::card{title="API Key Type Mismatch"}
  **Resolution Steps:**
  
  1. Verify you're using the correct API key type for your model.
  2. Use Codestral API key specifically for Codestral model.
  3. Use General API key for other Mistral models.
  :::

  :::card{title="Model Access Denied"}
  **Resolution Steps:**
  
  1. Verify your account has access to the selected model.
  2. Check billing status and account standing.
  3. Ensure API key hasn't expired or been revoked.
  :::
::


# Ollama

CodinIT.dev supports running models locally using Ollama. This approach offers privacy, offline access, and potentially reduced costs. It requires some initial setup and a sufficiently powerful computer. Because of the present state of consumer hardware, it's not recommended to use Ollama with CodinIT.dev as performance will likely be poor for average hardware configurations.

**Website:** <https://ollama.com/>{ariaLabel="Ollama Website" rel="nofollow"}

### Setting up Ollama

1. **Download and Install Ollama:**
   Obtain the Ollama installer for your operating system from the [Ollama website](https://ollama.com/){ariaLabel="Ollama Website" rel="nofollow"} and follow their installation guide. Ensure Ollama is running. You can typically start it with:
   ```bash
   ollama serve
   ```
2. **Download a Model:**
   Ollama supports a wide variety of models. A list of available models can be found on the [Ollama model library](https://ollama.com/library){ariaLabel="Ollama Model Library" rel="nofollow"}. Some models recommended for coding tasks include:
   - `codellama:7b-code` (a good, smaller starting point)
   - `codellama:13b-code` (offers better quality, larger size)
   - `codellama:34b-code` (provides even higher quality, very large)
   - `qwen2.5-coder:32b`
   - `mistralai/Mistral-7B-Instruct-v0.1` (a solid general-purpose model)
   - `deepseek-coder:6.7b-base` (effective for coding)
   - `llama3:8b-instruct-q5_1` (suitable for general tasks)
   :brTo download a model, open your terminal and execute:
   ```bash
   ollama pull <model_name>
   ```
   :brFor instance:
   ```bash
   ollama pull qwen2.5-coder:32b
   ```
3. **Configure the Model's Context Window:**
   By default, Ollama models often use a context window of 2048 tokens, which can be insufficient for many CodinIT.dev requests. A minimum of 12,000 tokens is advisable for decent results, with 32,000 tokens being ideal. To adjust this, you'll modify the model's parameters and save it as a new version. :br First, load the model (using `qwen2.5-coder:32b` as an example):
   ```bash
   ollama run qwen2.5-coder:32b
   ```
   :brOnce the model is loaded within the Ollama interactive session, set the context size parameter:
   ```text
   /set parameter num_ctx 32768
   ```
   :brThen, save this configured model with a new name:
   ```text
   /save your_custom_model_name
   ```
   :br(Replace `your_custom_model_name` with a name of your choice.)
4. **Configure CodinIT.dev:**
   - Open the CodinIT.dev sidebar (usually indicated by the CodinIT.dev icon).
   - Click the settings gear icon (‚öôÔ∏è).
   - Select "ollama" as the API Provider.
   - Enter the Model name you saved in the previous step (e.g., `your_custom_model_name`).
   - (Optional) Adjust the base URL if Ollama is running on a different machine or port. The default is `http://localhost:11434`.
   - (Optional) Configure the Model context size in CodinIT.dev's Advanced settings. This helps CodinIT.dev manage its context window effectively with your customized Ollama model.

### Tips and Notes

- **Resource Demands:** Running large language models locally can be demanding on system resources. Ensure your computer meets the requirements for your chosen model.
- **Model Choice:** Experiment with various models to discover which best fits your specific tasks and preferences.
- **Offline Capability:** After downloading a model, you can use CodinIT.dev with that model even without an internet connection.
- **Token Usage Tracking:** CodinIT.dev tracks token usage for models accessed via Ollama, allowing you to monitor consumption.
- **Ollama's Own Documentation:** For more detailed information, consult the official [Ollama documentation](https://ollama.com/docs){ariaLabel="Ollama Documentation" rel="nofollow"}.


# OpenAI

> Learn how to configure and use official OpenAI models with CodinIT.dev.

CodinIT.dev supports accessing models directly through the official OpenAI API.

**Website:** <https://openai.com/>{ariaLabel="OpenAI Website" rel="nofollow"}

### Getting an API Key

1. **Sign Up/Sign In:** Visit the [OpenAI Platform](https://platform.openai.com/){ariaLabel="OpenAI Platform" rel="nofollow"}. You'll need to create an account or sign in if you already have one.
2. **Navigate to API Keys:** Once logged in, go to the [API keys section](https://platform.openai.com/api-keys){ariaLabel="OpenAI API Keys Section" rel="nofollow"} of your account.
3. **Create a Key:** Click on "Create new secret key". It's good practice to give your key a descriptive name (e.g., "CodinIT.dev API Key").
4. **Copy the Key:** &#x2A;*Crucial:** Copy the generated API key immediately. For security reasons, OpenAI will not show it to you again. Store this key in a safe and secure location.

### Supported Models

CodinIT.dev is compatible with a variety of OpenAI models, including but not limited to:

- 'o3'
- `o3-mini` (medium reasoning effort)
- 'o4-mini'
- `o3-mini-high` (high reasoning effort)
- `o3-mini-low` (low reasoning effort)
- `o1`
- `o1-preview`
- `o1-mini`
- `gpt-4.5-preview`
- `gpt-4o`
- `gpt-4o-mini`
- 'gpt-4.1'
- 'gpt-4.1-mini'

For the most current list of available models and their capabilities, please refer to the official [OpenAI Models documentation](https://platform.openai.com/docs/models){ariaLabel="OpenAI Models Documentation" rel="nofollow"}.

### Configuration in CodinIT.dev

1. **Open CodinIT.dev Settings:** Click the settings gear icon (‚öôÔ∏è) in the CodinIT.dev panel.
2. **Select Provider:** Choose "OpenAI" from the "API Provider" dropdown menu.
3. **Enter API Key:** Paste your OpenAI API key into the "OpenAI API Key" field.
4. **Select Model:** Choose your desired model from the "Model" dropdown list.
5. **(Optional) Base URL:** If you need to use a proxy or a custom base URL for the OpenAI API, you can enter it here. Most users will not need to change this from the default.

### Tips and Notes

- **Pricing:** Be sure to review the [OpenAI Pricing page](https://openai.com/pricing){ariaLabel="OpenAI Pricing Page" rel="nofollow"} for detailed information on the costs associated with different models.
- **Azure OpenAI Service:** If you are looking to use the Azure OpenAI service, please note that specific documentation for Azure OpenAI with CodinIT.dev may be found separately, or you might need to configure it as an OpenAI-compatible endpoint if such functionality is supported by CodinIT.dev for custom configurations.


# Vertex AI

> Configure GCP Vertex AI with CodinIT.dev to access leading generative AI models like Claude 4 Sonnet v2. This guide covers GCP environment setup, authentication, and secure integration for enterprise teams.

### Overview

**GCP Vertex AI:**:br
A fully managed service that provides access to leading generative AI models‚Äîsuch as Anthropic's Claude 4 Sonnet v2‚Äîthrough Google Cloud. :br[Learn more about GCP Vertex AI](https://cloud.google.com/vertex-ai){rel="nofollow"}.

This guide is tailored for organizations with established GCP environments (leveraging IAM roles, service accounts, and best practices in resource management) to ensure secure and compliant usage.

---

### Step 1: Prepare Your GCP Environment

#### 1.1 Create or Use a GCP Project

- **Sign in to the GCP Console:**:br[Google Cloud Console](https://console.cloud.google.com/){rel="nofollow"}
- **Select or Create a Project:**:br
  Use an existing project or create a new one dedicated to Vertex AI.

#### 1.2 Set Up IAM Permissions and Service Accounts

- **Assign Required Roles:**
  - Grant your user (or service account) the **Vertex AI User** role (`roles/aiplatform.user`)
  - For service accounts, also attach the **Vertex AI Service Agent** role (`roles/aiplatform.serviceAgent`) to enable certain operations
  - Consider additional predefined roles as needed:

    - Vertex AI Platform Express Admin
    - Vertex AI Platform Express User
    - Vertex AI Migration Service User
- **Cross-Project Resource Access:**
  - For BigQuery tables in different projects, assign the **BigQuery Data Viewer** role
  - For Cloud Storage buckets in different projects, assign the **Storage Object Viewer** role
  - For external data sources, refer to the [GCP Vertex AI Access Control documentation](https://cloud.google.com/vertex-ai/docs/general/access-control){rel="nofollow"}

---

### Step 2: Verify Regional and Model Access

#### 2.1 Choose and Confirm a Region

Vertex AI supports multiple regions. Select a region that meets your latency, compliance, and capacity needs. Examples include:

- **us-east5 (Columbus, Ohio)**
- **us-central1 (Iowa)**
- **europe-west1 (Belgium)**
- **europe-west4 (Netherlands)**
- **asia-southeast1 (Singapore)**
- **global (Global)**

The Global endpoint may offer higher availability and reduce resource exhausted errors. Only Gemini models are supported.

#### 2.2 Enable the Claude 4 Sonnet v2 Model

- **Open Vertex AI Model Garden:**:br
  In the Cloud Console, navigate to **Vertex AI ‚Üí Model Garden**
- **Enable Claude 4 Sonnet v2:**:br
  Locate the model card for Claude 4 Sonnet v2 and click **Enable**

---

### Step 3: Configure the CodinIT.dev VS Code Extension

#### 3.1 Install and Open CodinIT.dev

- **Download VS Code:**:br[Download Visual Studio Code](https://code.visualstudio.com/){rel="nofollow"}
- **Install the CodinIT.dev Extension:**
  - Open VS Code
  - Navigate to the Extensions Marketplace (Ctrl+Shift+X or Cmd+Shift+X)
  - Search for **CodinIT.dev** and install the extension

![CodinIT.dev extension in VS Code](https://storage.googleapis.com/CodinIT.dev_public_images/docs/assets/CodinIT.dev-extension-arrow.png)

#### 3.2 Configure CodinIT.dev Settings

- **Open CodinIT.dev Settings:**:br
  Click the settings ‚öôÔ∏è icon within the CodinIT.dev extension
- **Set API Provider:**:br
  Choose **GCP Vertex AI** from the API Provider dropdown
- **Enter Your Google Cloud Project ID:**:br
  Provide the project ID you set up earlier
- **Select the Region:**:br
  Choose one of the supported regions (e.g., `us-east5`)
- **Select the Model:**:br
  From the available list, choose **Claude 4 Sonnet v2**
- **Save and Test:**:br
  Save your settings and test by sending a simple prompt (e.g., "Generate a Python function to check if a number is prime.")

---

### Step 4: Authentication and Credentials Setup

#### Option A: Using Your Google Account (User Credentials)

1. **Install the Google Cloud CLI:**:br
   Follow the [installation guide](https://cloud.google.com/sdk/docs/install){rel="nofollow"}
2. **Initialize and Authenticate:**
   ```bash
   gcloud init
   gcloud auth application-default login
   ```
   - This sets up Application Default Credentials (ADC) using your Google account
3. **Restart VS Code:**:br
   Ensure VS Code is restarted so that the CodinIT.dev extension picks up the new credentials

#### Option B: Using a Service Account (JSON Key)

1. **Create a Service Account:**
   - In the GCP Console, navigate to **IAM & Admin > Service Accounts**
   - Create a new service account (e.g., "vertex-ai-client")
2. **Assign Roles:**
   - Attach **Vertex AI User** (`roles/aiplatform.user`)
   - Attach **Vertex AI Service Agent** (`roles/aiplatform.serviceAgent`)
   - Optionally, add other roles as required
3. **Generate a JSON Key:**
   - In the Service Accounts section, manage keys for your service account and download the JSON key
4. **Set the Environment Variable:**
   ```bash
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-key.json"
   ```
   - This instructs Google Cloud client libraries (and CodinIT.dev) to use this key
5. **Restart VS Code:**:br
   Launch VS Code from a terminal where the `GOOGLE_APPLICATION_CREDENTIALS` variable is set

---

### Step 5: Security, Monitoring, and Best Practices

#### 5.1 Enforce Least Privilege

- **Principle of Least Privilege:**:br
  Only grant the minimum necessary permissions. Custom roles can offer finer control compared to broad predefined roles
- **Best Practices:**:br
  Refer to [GCP IAM Best Practices](https://cloud.google.com/iam/docs/best-practices){rel="nofollow"}

#### 5.2 Manage Resource Access

- **Project vs. Resource-Level Access:**:br
  Access can be managed at both levels. Note that resource-level permissions (e.g., for BigQuery or Cloud Storage) add to, but do not override, project-level policies

#### 5.3 Monitor Usage and Quotas

- **Model Observability Dashboard:**
  - In the Vertex AI Console, navigate to the **Model Observability** dashboard
  - Monitor metrics such as request throughput, latency, and error rates (including 429 quota errors)
- **Quota Management:**
  - If you encounter 429 errors, check the **IAM & Admin > Quotas** page
  - Request a quota increase if necessary :br[Learn more about GCP Vertex AI Quotas](https://cloud.google.com/vertex-ai/docs/quotas){rel="nofollow"}

#### 5.4 Service Agents and Cross-Project Considerations

- **Service Agents:**:br
  Be aware of the different service agents:
  - Vertex AI Service Agent
  - Vertex AI RAG Data Service Agent
  - Vertex AI Custom Code Service Agent
  - Vertex AI Extension Service Agent
- **Cross-Project Access:**:br
  For resources in other projects (e.g., BigQuery, Cloud Storage), ensure that the appropriate roles (BigQuery Data Viewer, Storage Object Viewer) are assigned

---

### Conclusion

By following these steps, your enterprise team can securely integrate GCP Vertex AI with the CodinIT.dev VS Code extension to harness the power of **Claude 4 Sonnet v2**:

- **Prepare Your GCP Environment:**:br
  Create or use a project, configure IAM with least privilege, and ensure necessary roles (including the Vertex AI Service Agent role) are attached
- **Verify Regional and Model Access:**:br
  Confirm that your chosen region supports Claude 4 Sonnet v2 and that the model is enabled
- **Configure CodinIT.dev in VS Code:**:br
  Install CodinIT.dev, enter your project ID, select the appropriate region, and choose the model
- **Set Up Authentication:**:br
  Use either user credentials (via `gcloud auth application-default login`) or a service account with a JSON key
- **Implement Security and Monitoring:**:br
  Adhere to best practices for IAM, manage resource access carefully, and monitor usage with the Model Observability dashboard

For further details, please consult the [GCP Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs){rel="nofollow"} and your internal security policies. :br
Happy coding!

*This guide will be updated as GCP Vertex AI and CodinIT.dev evolve. Always refer to the latest documentation for current practices.*


# Together AI

CodinIT supports accessing open-source AI models through the Together AI platform, providing access to Llama 3.1, Code Llama, Mixtral, and other community-built models with transparent pricing.

::callout{icon="i-lucide-info"}
**Together AI** provides fast, affordable access to the best open-source AI models with transparent pricing and no vendor lock-in.
::

## Getting an API Key

::steps
### Sign Up for Together AI

Visit the [Together AI Platform](https://api.together.xyz/){ariaLabel="Together AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Qwen 2.5"}
  A powerful model with a balance of intelligence and speed.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Together AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Together AI API key into the "Together AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::


# Fireworks AI

CodinIT supports accessing high-performance AI models through the Fireworks AI platform, providing ultra-fast inference for Llama 3.1, Mixtral, Code Llama, and other open-source models.

::callout{icon="i-lucide-zap"}
**Fireworks AI** specializes in ultra-fast inference with industry-leading response times and production-ready performance for open-source AI models.
::

## Getting an API Key

::steps
### Sign Up for Fireworks AI

Visit the [Fireworks AI Platform](https://fireworks.ai/){ariaLabel="Fireworks AI Platform" rel="nofollow"} and create an account.

### Navigate to API Keys

Once logged in, go to the **API Keys** section in your account dashboard.

### Create Your API Key

Click on **"Create API Key"** and give it a descriptive name.

### Secure Your Key

Copy the generated API key immediately and store it securely.
::

## Supported Models

::card-group
  :::card{icon="i-lucide-box" title="Llama 3.1"}
  The latest and most advanced model from Meta.
  :::

  :::card{icon="i-lucide-box" title="Code Llama"}
  A powerful model specialized in code-related tasks.
  :::

  :::card{icon="i-lucide-box" title="Mixtral"}
  A powerful model with a balance of intelligence and speed.
  :::

  :::card{icon="i-lucide-box" title="Starcoder"}
  A powerful model specialized in code-related tasks.
  :::
::

## Configuration in CodinIT

::steps
### Open CodinIT Settings

Click the settings gear icon (‚öôÔ∏è) in the CodinIT panel.

### Select Provider

Choose **"Fireworks AI"** from the "API Provider" dropdown menu.

### Enter API Key

Paste your Fireworks AI API key into the "Fireworks AI API Key" field.

### Select Model

Choose your desired model from the "Model" dropdown list.
::
