[{"data":1,"prerenderedAt":264},["ShallowReactive",2],{"navigation":3,"/providers/fireworks":105,"/providers/fireworks-surround":261},[4,28,45,91],{"title":5,"path":6,"stem":7,"children":8,"icon":27},"Getting Started","/getting-started","1.getting-started/1.index",[9,12,17,22],{"title":10,"path":6,"stem":7,"icon":11},"Introduction","i-lucide-house",{"title":13,"path":14,"stem":15,"icon":16},"Quickstart","/getting-started/quickstart","1.getting-started/2.quickstart","i-lucide-zap",{"title":18,"path":19,"stem":20,"icon":21},"Teams","/getting-started/teams","1.getting-started/3.teams","i-lucide-users",{"title":23,"path":24,"stem":25,"icon":26},"Developer Docs","/getting-started/developer-docs","1.getting-started/4.developer-docs","i-heroicons-rocket-launch","i-lucide-rocket",{"title":29,"icon":30,"path":31,"stem":32,"children":33,"page":44},"Integrations","i-lucide-infinity","/integrations","2.integrations",[34,39],{"title":35,"path":36,"stem":37,"icon":38},"GitHub","/integrations/github","2.integrations/1.github","i-simple-icons-github",{"title":40,"path":41,"stem":42,"icon":43},"Plugins","/integrations/plugins","2.integrations/2.plugins","i-lucide-plug-zap",false,{"title":46,"icon":47,"path":48,"stem":49,"children":50,"page":44},"Models","i-lucide-cpu","/models","3.models",[51,56,61,66,71,76,81,86],{"title":52,"path":53,"stem":54,"icon":55},"Anthropic","/models/anthropic","3.models/1.anthropic","i-simple-icons-anthropic",{"title":57,"path":58,"stem":59,"icon":60},"DeepSeek","/models/deepseek","3.models/2.deepseek","i-lucide-search",{"title":62,"path":63,"stem":64,"icon":65},"Google Gemini","/models/gemini","3.models/4.gemini","i-simple-icons-googlegemini",{"title":67,"path":68,"stem":69,"icon":70},"xAI Groq","/models/groq","3.models/5.groq","i-lucide-bot",{"title":72,"path":73,"stem":74,"icon":75},"Mistral","/models/mistral","3.models/6.mistral","i-lucide-wind",{"title":77,"path":78,"stem":79,"icon":80},"Ollama","/models/ollama","3.models/7.ollama","i-lucide-server",{"title":82,"path":83,"stem":84,"icon":85},"OpenAI","/models/openai","3.models/8.openai","i-simple-icons-openai",{"title":87,"path":88,"stem":89,"icon":90},"Vertex AI","/models/gcp-vertex-ai","3.models/9.gcp-vertex-ai","i-simple-icons-google",{"title":92,"icon":93,"path":94,"stem":95,"children":96,"page":44},"Providers","i-lucide-cloud","/providers","4.providers",[97,101],{"title":98,"path":99,"stem":100,"icon":21},"Together AI","/providers/togetherai","4.providers/1.togetherai",{"title":102,"path":103,"stem":104,"icon":16},"Fireworks AI","/providers/fireworks","4.providers/2.fireworks",{"id":106,"title":102,"body":107,"description":254,"extension":255,"links":256,"meta":257,"navigation":258,"path":103,"seo":259,"stem":104,"__hash__":260},"docs/4.providers/2.fireworks.md",{"type":108,"value":109,"toc":246},"minimark",[110,114,123,128,176,180,208,212],[111,112,113],"p",{},"CodinIT supports accessing high-performance AI models through the Fireworks AI platform, providing ultra-fast inference for Llama 3.1, Mixtral, Code Llama, and other open-source models.",[115,116,117],"callout",{"icon":16},[111,118,119,122],{},[120,121,102],"strong",{}," specializes in ultra-fast inference with industry-leading response times and production-ready performance for open-source AI models.",[124,125,127],"h2",{"id":126},"getting-an-api-key","Getting an API Key",[129,130,131,136,147,151,158,162,169,173],"steps",{},[132,133,135],"h3",{"id":134},"sign-up-for-fireworks-ai","Sign Up for Fireworks AI",[111,137,138,139,146],{},"Visit the ",[140,141,142],"a",{"ariaLabel":142,"href":143,"rel":144},"Fireworks AI Platform","https://fireworks.ai/",[145],"nofollow"," and create an account.",[132,148,150],{"id":149},"navigate-to-api-keys","Navigate to API Keys",[111,152,153,154,157],{},"Once logged in, go to the ",[120,155,156],{},"API Keys"," section in your account dashboard.",[132,159,161],{"id":160},"create-your-api-key","Create Your API Key",[111,163,164,165,168],{},"Click on ",[120,166,167],{},"\"Create API Key\""," and give it a descriptive name.",[132,170,172],{"id":171},"secure-your-key","Secure Your Key",[111,174,175],{},"Copy the generated API key immediately and store it securely.",[124,177,179],{"id":178},"supported-models","Supported Models",[181,182,183,191,197,203],"card-group",{},[184,185,188],"card",{"icon":186,"title":187},"i-lucide-box","Llama 3.1",[111,189,190],{},"The latest and most advanced model from Meta.",[184,192,194],{"icon":186,"title":193},"Code Llama",[111,195,196],{},"A powerful model specialized in code-related tasks.",[184,198,200],{"icon":186,"title":199},"Mixtral",[111,201,202],{},"A powerful model with a balance of intelligence and speed.",[184,204,206],{"icon":186,"title":205},"Starcoder",[111,207,196],{},[124,209,211],{"id":210},"configuration-in-codinit","Configuration in CodinIT",[129,213,214,218,221,225,232,236,239,243],{},[132,215,217],{"id":216},"open-codinit-settings","Open CodinIT Settings",[111,219,220],{},"Click the settings gear icon (⚙️) in the CodinIT panel.",[132,222,224],{"id":223},"select-provider","Select Provider",[111,226,227,228,231],{},"Choose ",[120,229,230],{},"\"Fireworks AI\""," from the \"API Provider\" dropdown menu.",[132,233,235],{"id":234},"enter-api-key","Enter API Key",[111,237,238],{},"Paste your Fireworks AI API key into the \"Fireworks AI API Key\" field.",[132,240,242],{"id":241},"select-model","Select Model",[111,244,245],{},"Choose your desired model from the \"Model\" dropdown list.",{"title":247,"searchDepth":248,"depth":249,"links":250},"",1,2,[251,252,253],{"id":126,"depth":249,"text":127},{"id":178,"depth":249,"text":179},{"id":210,"depth":249,"text":211},"Learn how to connect Fireworks AI to your CodinIT projects for ultra-fast inference of open-source models.","md",null,{},{"icon":16},{"title":102,"description":254},"S7n4UM_cRdRWow_3LcBJQOaDnm94bTq4J-Y9ohJMSFE",[262,256],{"title":98,"path":99,"stem":100,"description":263,"icon":21,"children":-1},"Learn how to connect Together AI to your CodinIT projects to access open-source AI models with transparent pricing.",1753480437125]